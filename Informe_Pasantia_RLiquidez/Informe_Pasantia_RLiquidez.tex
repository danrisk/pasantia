\documentclass[10pt,]{article}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
\else % if luatex or xelatex
  \ifxetex
    \usepackage{mathspec}
  \else
    \usepackage{fontspec}
  \fi
  \defaultfontfeatures{Ligatures=TeX,Scale=MatchLowercase}
\fi
% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
% use microtype if available
\IfFileExists{microtype.sty}{%
\usepackage{microtype}
\UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\usepackage{hyperref}
\hypersetup{unicode=true,
            pdfborder={0 0 0},
            breaklinks=true}
\urlstyle{same}  % don't use monospace font for urls
\usepackage{longtable,booktabs}
\IfFileExists{parskip.sty}{%
\usepackage{parskip}
}{% else
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
% % \setcounter{secnumdepth}{0}
% % % % Redefines (sub)paragraphs to behave more like sections
% \ifx\paragraph\undefined\else
% \let\oldparagraph\paragraph
% \renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
% \fi
% \ifx\subparagraph\undefined\else
% \let\oldsubparagraph\subparagraph
% \renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
% \fi
% 
%%% Use protect on footnotes to avoid problems with footnotes in titles
\let\rmarkdownfootnote\footnote%
\def\footnote{\protect\rmarkdownfootnote}

%%% Change title format to be more compact
\usepackage{titling}

% Create subtitle command for use in maketitle
\newcommand{\subtitle}[1]{
  \posttitle{
    \begin{center}\large#1\end{center}
    }
}

\setlength{\droptitle}{-2em}
  \title{}
  \pretitle{\vspace{\droptitle}}
  \posttitle{}
  \author{}
  \preauthor{}\postauthor{}
  \date{}
  \predate{}\postdate{}

\usepackage{geometry}
\usepackage{fancyhdr}
\usepackage{color}
\usepackage{lastpage}
\usepackage{anysize}
\usepackage{microtype}
\usepackage{fourier}
\usepackage{cabin}
\usepackage{cancel}
\usepackage[x11names]{xcolor}
\usepackage{graphicx}
\papersize{27.9cm}{21.5cm}
\marginsize{1.0cm}{2.0cm}{2.0cm}{2.0cm}
\pagestyle{fancy}
\lhead{\includegraphics[width=40px]{/Users/danny/Documents/Pasantia/img/UCV.png}}
\rhead{\includegraphics[width=40px]{/Users/danny/Documents/Pasantia/img/SUDEBAN.png}}
\lfoot{Trabajo de Pasantía}
\cfoot{}
\rfoot{\textcolor[gray]{0.2}{(\thepage\ de \pageref{LastPage})}}
\renewcommand{\headrule}{\hbox to\headwidth{\color{gray40}\leaders\hrule height \footrulewidth\hfill}}
\renewcommand{\headrulewidth}{2pt}
\renewcommand{\footrule}{\hbox to\headwidth{\color{gray40}\leaders\hrule height \footrulewidth\hfill}}
\pagestyle{fancy}
\renewcommand{\footrulewidth}{2pt}
%\renewcommand{\rmdefault}{phv}
%\renewcommand{\sfdefault}{phv}
\renewcommand{\sfdefault}{qag}
\renewcommand{\contentsname}{Contenido}
\setlength{\headsep}{1.5cm}
\setlength{\voffset}{-1cm}

\usepackage[explicit]{titlesec}

\definecolor{azulvision}{HTML}{182f58}
\definecolor{naranjavision}{HTML}{ff6800}
\definecolor{gray40}{gray}{0.40}
\newcommand{\hsp}{\hspace{10pt}}
\titleformat{\section}[hang]{\huge\bfseries}{\textcolor{azulvision}{\thesection}\hsp\textcolor{gray40}{|}\hsp}{0pt}{\textcolor{azulvision}{#1}\huge\bfseries}
\titleformat{\subsection}[hang]{\Large\bfseries}{\textcolor{azulvision}{\thesubsection}\hsp\textcolor{gray40}{|}\hsp}{0pt}{\textcolor{azulvision}{#1}\Large\bfseries}
\titleformat{\subsubsection}[hang]{\large\bfseries}{\textcolor{azulvision}{\thesubsubsection}\hsp\textcolor{gray40}{|}\hsp}{0pt}{\textcolor{azulvision}{#1}\large\bfseries}
\setcounter{secnumdepth}{4}
\titleformat{\paragraph}[hang]{\normalsize\bfseries}{\textcolor{azulvision}{\theparagraph}\hsp\textcolor{gray40}{|}\hsp}{0pt}{\textcolor{azulvision}{#1}\normalsize\bfseries}


\begin{document}

\begin{titlepage}
\newgeometry{left=7.5cm} %defines the geometry for the titlepage
\pagecolor{gray40}
\noindent
\includegraphics[width=5cm]{/Users/danny/Documents/Pasantia/img/UCV.png}\\[-1em]
\color{white}
\makebox[0pt][l]{\rule{1.3\textwidth}{1pt}}
\par
\noindent
\textbf{\textsf{Un Enfoque Actuarial}}\\
\Huge\textbf{Riesgo de Liquidez} \\ \\
\vfill
\noindent
\small{\textbf{\today}} \\ \\
\end{titlepage}
\restoregeometry % restores the geometry
\nopagecolor% Use this to restore the color pages to white

\tableofcontents

\hypertarget{descripcion-de-la-organizacion}{%
\section{Descripción de la
Organización}\label{descripcion-de-la-organizacion}}

\begin{itemize}
\item
  Razón Social: Superintendencia del Sector Bancario
\item
  Domicilio Fiscal: Avenida Francisco de Miranda, Urbanización La
  Carlota, Edificio Centro Empresarial Parque del Este, Municipio Sucre,
  Parroquia Leoncio Martínez, Apartado Postal 6761, Código Postal 1071,
  Caracas, República Bolivariana de Venezuela.
\item
  Teléfonos:
\item
  Master: (0212) 280-69-33.
\item
  0800-SUDEBAN (7833226).
\item
  Fax: (0212) 238-25-16.
\item
  Email:
  \href{mailto:webmaster@sudeban.gob.ve}{\nolinkurl{webmaster@sudeban.gob.ve}}
\item
  Página: www.sudeban.gob.ve
\end{itemize}

\hypertarget{resena-historica}{%
\subsection{Reseña Histórica}\label{resena-historica}}

La Superintendencia del Sector Bancario (SUDEBAN), es un organismo
autónomo, fundado en 1940, de carácter técnico especializado, con
personalidad jurídica y patrimonio propio e independiente del Fisco
Nacional que tiene como función principal supervisar, controlar y
vigilar a las instituciones financieras regidas por el Decreto con
Rango, Valor y Fuerza de Ley de Reforma Parcial de la Ley General de
Bancos.

SUDEBAN, es un ente adscrito del Ministerio del Poder Popular de
Economía y Finanzas, a los efectos de tutela administrativa, gozando de
las prerrogativas, privilegios y exenciones de orden fiscal, tributario
y procesal, que la Ley otorga a la República. La SUDEBAN, gozará de
autonomía funcional, administrativa y financiera en el ejercicio de sus
funciones en los términos establecidos en la Ley.

Para cumplir con sus funciones, la institución posee ingresos propios
obtenidos mediante los aportes de los sujetos obligados del Sistema
Bancario Nacional.

\hypertarget{filosofia-de-gestion}{%
\subsection{Filosofía de Gestión}\label{filosofia-de-gestion}}

\begin{itemize}
\tightlist
\item
  \textbf{Misión:} Ser una Institución conformada por un talento humano
  comprometido con la supervisión y regulación del Sector Bancario a
  través de la aplicación de las mejores prácticas nacionales e
  internacionales, que contribuyan con la estabilidad del sistema y el
  desarrollo nacional.
\item
  \textbf{Visión:} Ser modelo de institución pública inspiradora de
  confianza y credibilidad de reconocido prestigio nacional e
  internacional.
\item
  \textbf{Principios:} La Superintendencia del Sector Bancario como ente
  de la Administración Pública está al servicio de los ciudadanos y
  ciudadanas, por lo tanto, el desarrollode las actividades de este
  Organismo están fundamentadas en los principios contenidos en el
  artículo 141 de la Constitución Nacional. Por tanto, la labor de
  SUDEBAN estará basada en sólidos principios que fortalezcan sus
  procesos y orienten las competencias del personal con:

  \begin{itemize}
  \tightlist
  \item
    Eficacia: En cuanto al cumplimiento de los objetivos, metas,
    actividades y tareas.
  \item
    Eficiencia: En la utilización racional de los recursos disponibles.
  \item
    Transparencia y Buena Fe: En el suministro, recepción y manejo de
    información oportuna, veráz y accesible por igual a todos los
    sectores sociales, sobre la gestión, actuaciones administrativas y
    manejo de los recursos asignados.
  \item
    Rendición de Cuentas y Responsabilidad en el ejercicio: En cuanto a
    la presentación oportuna de los resultados de la gestión y el
    cumplimiento de las funciones ante los poderes y órganos públicos
    competentes, en la materia y el colectivo social.
  \end{itemize}
\end{itemize}

\hypertarget{valores}{%
\subsection{Valores}\label{valores}}

\begin{itemize}
\tightlist
\item
  \textbf{Responsabilidad:} Se traduce en la mayor disposición y
  diligencia en el cumplimiento de las competencias, funciones y tareas
  encomendadas. Así como, la permanente disposición a rendir cuentas y a
  asumir las consecuencias de la conducta pública sin excusas de ninguna
  naturaleza, cuando se requiera o juzgue necesario.
\item
  \textbf{Ética:} Conlleva a realizar las labores con eficiencia y a
  mantener una actitud de rechazo frente a todo lo que minimice la
  dignidad y la moral en el cumplimiento y ejercicio de las funciones.
\item
  \textbf{Transparencia:} Exige la ejecución diáfana de los actos del
  servicio, e implica que estos son accesibles al conocimiento de toda
  persona natural y jurídica que tenga interés legítimo en el asunto.
\item
  \textbf{Compromiso:} Es poner al máximo las capacidades individuales
  para sacar adelante todo aquello que se ha confiado. Cuando se
  establece un compromiso es porque se conocen las condiciones que se
  están aceptando y las obligaciones que éstas conllevan.
\item
  \textbf{Equidad:} Esta refereida a la adecuación respecto a las
  personas que dirijan peticiones, sin ningún tipo de preferencias y
  solo en razón del mérito, legalidad, motivaciones objetivas y sin
  consideranción de género, religión, etnia, posición social y económica
  u otras características ajenas del fondo del asunto y la justicia.
\item
  \textbf{Excelencia:} Conjunto de prácticas sobresalientes en la
  gestión de la Institucion y el logro de resultados basados en
  conceptos fundamentales que incluyen la orientación al servicio y
  hacia los resultados, liderazgo, implicación de las personas, calidad,
  mejora continua, innovación y responsabilidad social.
\item
  \textbf{Respeto:} Sentimiento de alta consideración hacia los
  ciudadanos y entidades. Capacidades de aceptar los diferentes
  criterios y actitudes dentro de la filosofía de la institución.
\end{itemize}

\hypertarget{estructura-organizativa.}{%
\subsection{Estructura Organizativa.}\label{estructura-organizativa.}}

Right Box This is the first box. Box 8 1 And this is the second

\hypertarget{terminologia-basica.}{%
\section{Terminología Básica.}\label{terminologia-basica.}}

Ante de adentranos en el tema principal, vamos a realizar un repaso de
algunas definiciones que usaremos para definir toda la maquinaria que
esta detras del riesgo de liquidez.

\begin{itemize}
\item
  \textbf{Banco} : Los Bancos son empresas que se dedican a realizar
  operaciones financieras con el dinero procedente de sus accionistas y
  de los depósitos de sus clientes, de esta forma lo definine la Real
  Academia Española. A partir de ahora consideraremos las instituciones
  que se rigen conforme a lo establecido en las leyes generales de los
  bancos, llamados Bancos Universales y microfinancieros, los mismos
  están bajo la supervición de la SUDEBAN (Superintendencia de las
  Instituciones del Sector Bancario).
\item
  \textbf{Fondos Bancarios} : Los bancos obtienen
\item
  \textbf{SUDEBAN} : Sus siglas significan Superintendencia del las
  Instituciones del Sector Bancario, esta institución tiene como
  objetivo principal regular y supervisar a las Instituciones del Sector
  Bancario, mediante la aplicación de las mejores prácticas nacionales e
  internacionales, que contribuyan con la estabilidad del sector y el
  desarrollo nacional. La página web de esta institución es
  \url{http://sudeban.gob.ve}.
\item
  \textbf{Riesgo} : El riesgo lo definiremos como una probabilidad de
  que ocurra un hecho, o acontecimiento, que lleve a pérdidas
  materiales, como el resultado de operaciones que desarrolle el banco.
\item
  \textbf{Gestión Integral de Riesgo} : Estructura para aplicar
  políticas mediante alertas o mecanismos de reporte de acciones
  ejecutivas, con el objetivo principal de minimizar el riesgo
  utilizando recursos gerenciales. Las etapas principales son:

  \begin{itemize}
  \tightlist
  \item
    \textbf{Mitigación} : Medidas que deben tomarse para disminuir el
    impacto de fenómenos peligrosos.
  \item
    \textbf{Preparación} : Acciones para asegurar la disponibilidad de
    recursos y a su vez la efectividad para enfrentar situaciones
    peligrosas.
  \item
    \textbf{Atención} : Respuestas para proteger bienes ante la
    ocurrencia de un evento adverso.
  \item
    \textbf{Rehabilitación} : Colocación en funcionamiento de los
    servicios afectados por un evento adverso.
  \item
    \textbf{Recuperación} : Paso donde se deben aplicar condiciones que
    reactiven los bienes afectados.
  \item
    \textbf{Evaluación} : Estimar los riesgos.
  \item
    \textbf{Información} : Generar y transmitir información oportuna
    según el plan de negocio establecido por el banco, donde se incluyan
    deficiencias o desviaciones, y sus respectivas
    correcciones.encontradas y su corrección.
  \end{itemize}
\item
  \textbf{Liquidez} : Cuando nos referimos a liquidez hablamos de la
  disposición que tiene un banco para satisfacer retiros efectuados por
  los depositantes y también la disposición de poder proporcionar
  préstamos a los clientes sin incurrir en faltas o pérdidas
  significativas.
\item
  \textbf{Riesgo de liquidez} : Probabilidad que tiene un banco de no
  poseer los fondos necesarios para hacer frente a sus obligaciones.
  Éste se manifiesta como la incapacidad que tienen los bancos de
  comprar u obtener los fondos necesarios para cumplir con las
  obligaciones que se les presenten, sin incurrir a pérdidas
  inaceptables. Cuando un banco no está en capacidad de enfrentar sus
  obligaciones se dice que cae en \textbf{iliquidez}, usualmente cuando
  esto sucede se puede implementar vender las inversiones del banco o
  parte de su cartera de créditos para obtener efectivo de manera
  rápida, y así solventar el problema.
\item
  \textbf{Tesorería} : La tesorería de un Banco es el área encargada de
  gestionar, organizar y controlar las operaciones que tienen que ver
  con los flujos de caja, o monetario. Tiene como función principal
  colocar en el mercado financiero os excedentes de dinero, o acudir al
  mercado a adquirir todo el dinero que necesite. Así podemos ver la
  tesorería como el conjunto de actividades relacionadas con la
  contabilidad del banco, revelando los pagos y los cobros. Toma medidas
  para que no se produzcan incumplimiento de pagos y los cobros para que
  siempre haya dinero. La tesorería consta de las siguientes áreas:

  \begin{itemize}
  \item
    \textbf{Front office} : Es donde se realizan las negociaciones de
    operaciones, como mantener las operaciones con los clientes y
    aspectos comerciales que se deriven de éstas. Ofrecen servios de
    consultoría, de forma de guiar a los corporativos para la emisión,
    colocación y utilización de instrumentos y sus derivados.
  \item
    \textbf{Middle office} : Se encarga de la medición, análisis y
    gestión de los riesgos de mercado, liquidez y operación en función
    de las presupuestadas a ser realizadas por el área de ejecución y
    gestión de operaciones de tesorería. Para el cálculo de los riesgo
    utilizan metodologías como el Valor de Riesgo, llevan trabajos de
    auditoria y control interno.
  \item
    \textbf{Back office} : Encargada de realizar aspectos operativos de
    la tesorería, como la liquidación, documentación, registro contable
    y conciliación de las operaciones, entre otros. También tienen a su
    cargo el adecuado manejo de bases de datos y registros informaticos,
    manteniendo y supervisando los sistemas.
  \end{itemize}
\item
  \textbf{Activos líquidos} : Cuando nos referimos a activos líquidos
  los definimos como aquellos que pueden convertirse en dinero en
  efectivo sin perder valor a corto plazo. Se les suele denominar
  \textbf{partidas equivalentes de efectivo} a aquellas inversiones que
  son de gran liquidez y tienen con ellos riesgos pocos significativos.
  Otros activos líquidos son los llamados \textbf{pasivos de vencimiento
  inmediato}, estos son activos vencidos contraidos por el banco, por lo
  tanto, se pueden reclamar en cualquier momento.
\item
  \textbf{Razón de liquidez} : Este tasa nos dice la capacidad que tiene
  el banco de realizar pagos a corto plazo, se define como la división,
  o cociente, de los activos líquidos y los pasivos de vencimiento
  inmediato.
\item
  \textbf{Operaciones contingentes} : Las operaciones contingentes es
  una operación donde se involucran dos partes, el fiador y el deudor,
  estas suceden a raíz de eventos inesperados. Es un documentos
  irrevocable, que lleva la obligación del deudor a cumplir con el
  fiador de forma incondicional. Estas operaciones se dividen en dos:

  \begin{itemize}
  \tightlist
  \item
    Operaciones contingentes activas:
  \item
    Operaciones contingentes pasivas:
  \end{itemize}
\end{itemize}

\textbf{Pasivo contingente} : Toda obligación posible, surgida a raíz de
sucesos pasados, cuya existencia quedará confirmada sólo si llegan a
ocurrir, o en caso contrario si no llegan a ocurrir, uno o más sucesos
futuros inciertos que no están enteramente bajo el control de la
entidad; o toda obligación presente, surgida a raíz de sucesos pasados,
pero no reconocida en los estados financieros, ya que: (i) no es
probable que por la existencia de la misma, y para satisfacerla, se
requiera que la entidad tenga que desprenderse de recursos que
incorporen beneficios económicos; o (ii) el importe de la obligación no
puede ser medido con la suficiente fiabilidad. La entidad no debe
proceder a reconocer contablemente una obligación de carácter
contingente. Por el contrario, deberá informar acerca de la obligación
en cuestión los estados financieros, salvo en el caso de que la salida
de recursos que incorporen beneficios económicos tenga una probabilidad
remota.

\textbf{Activo contingente} : La Norma define un activo contingente como
un activo posible, surgido a raíz de sucesos pasados, y cuya existencia
ha de ser confirmada por la ocurrencia, o en su caso por la no
ocurrencia, de uno o más eventos inciertos en el futuro, que no están
enteramente bajo el control de la entidad. Un ejemplo de activo
contingente es una reclamación a través de procesos legales, que la
entidad haya podido emprender, cuyo desenlace final sea incierto. La
entidad debe abstenerse de reconocer cualquier activo de carácter
contingente. No obstante, debe informar en los estados financieros sobre
la existencia del mismo, siempre y cuando sea probable la entrada de
beneficios económicos por esta causa. Cuando la realización del ingreso
sea prácticamente cierta, el activo relacionado no es de carácter
contingente, y su reconocimiento en los estados financieros resulta
apropiado.

\begin{itemize}
\tightlist
\item
  \textbf{Banda Temporal} : Días continuos pertenecientes a un mismo
  intervalo de tiempo. Generalmente los intervalos que se usan son los
  siguientes:
\end{itemize}

\begin{longtable}[]{@{}c@{}}
\toprule
Intervalos\tabularnewline
\midrule
\endhead
Del día 1 al 7\tabularnewline
Del día 8 al 15\tabularnewline
Del día 16 al último día del mes\tabularnewline
Del mes 2, de 31 a 60 días\tabularnewline
Del mes 3, de 61 a 90 días\tabularnewline
Del trimestre siguiente, de 91 a 180 días\tabularnewline
Del semestre siguiente, de 181 a 360 días\tabularnewline
De 12 meses, de 361 a 720\tabularnewline
Más de 12 meses, 721 o más días\tabularnewline
\bottomrule
\end{longtable}

\begin{itemize}
\tightlist
\item
  \textbf{Brecha de liquidez simple} : Esta brecha se define como la
  diferencia entre los flujos de entrada y de salida con lo que podemos
  contar en una banda temporal. Entre los flujos de entrada se puede
  tener recuperación de activos, inversiones liquidas y
  disponibilidades; en los flujos de salida podemos tener pagos de
  pasivos y aumento de activos.
\end{itemize}

Otra terminología que podemos conseguir es la siguiente: nos
encontraremos con \textbf{calce de plazo} cuando los flujos de entrada
son iguales a los flujos de salida, y \textbf{descalce de plazo}, cuando
los flujos no son iguales, en éste podemos tener un descalce de plazo
positivo, en el cual los flujos de entrada son mayores que los flujos de
salida y negativos en caso contrario.

\begin{itemize}
\tightlist
\item
  \textbf{Brecha de liquidez acumulada} : Es la suma acumulada de las
  brechas simples anteriores a la banda donde se este calculando y la de
  la misma banda.
\end{itemize}

\hypertarget{introduccion}{%
\section{Introducción}\label{introduccion}}

En este trabajo coadyuvamos la necesidad que representa para el Sistema
Bancario Nacional determinar, caracterizar y cuantificar el impacto que
genera las fluctuaciones de captaciones del público, la cuantificación
de la relación entre los Activos y Pasivos de las Instituciones
Financieras con el objeto de dar cumplimiento a lo establecido en las
resoluciones 136.03 ``Normas para una Adecuada Administración Integral
de Riesgos'' y 136.15 ``Normas Relativas a la Adecuada Administración
Integral del Riesgo de Liquidez de los Bancos'' emitidas por el
Organismo Regulador.

Por otra parte, tradicionalmente la evaluación de este riesgo se basa en
el supuesto en el cual horizonte de tiempo de las cuentas, portafolios o
instrumentos sometidos a la evaluación están ``Congelados'', en este
trabajo tomaremos un enfoque actuarial AAFIR (Actuarial Approach
Financial Risk), la cual implica que este supuesto es dinámico.
Aplicaremos un conjunto de técnicas estadísticas desde estadística
descriptiva, pasando por Pruebas de Bondad de Ajustes, Optimización de
Parámetros, Criterios de entropía y simulación de variables aleatorias
compuestas. Ademas todo este trabajo fue desarrollado en lenguaje R,
siendo el resultado un paquete de R de nombre ``Rliquidez''.

\hypertarget{pruebas-de-bondad-de-ajuste}{%
\section{Pruebas de Bondad de
Ajuste}\label{pruebas-de-bondad-de-ajuste}}

\hypertarget{representacion-de-los-datos-y-el-modelo.}{%
\subsection{Representación de los Datos y el
Modelo.}\label{representacion-de-los-datos-y-el-modelo.}}

Una de las fases fundamentales para garantizar el inicio de la
supervisión en materia estadística es el control de la calidad de los
datos. Los mismos deben ser congruentes, no contar con repeticiones
abruptas ni signos de manipulación o intervención; su hallazgo puede ser
síntoma de sesgo de los datos, lo que inutilizaría los modelos de
estimación y control.

Particularmente, se debe observar la Distribución de Frecuencia de los
datos y su respectivo gráfico pues de esta manera el especialista podría
detectar cualquier anomalía a priori en el justo momento de entrega de
los datos.

\hypertarget{contrastes-de-hipotesis.}{%
\subsection{Contrastes de Hipótesis.}\label{contrastes-de-hipotesis.}}

En esta sección aborda lo concerniente a los contrastes de hipótesis,
entendiendose como un sistema de toma de decisiones entre una variedad
de métodos estadisticos. Para la siguientes pruebas se definen las
hipótesis a contrastar:

\(H_0:\)La Data proviene de una Población con Distribución
Probabilística Definida.\\
\(H_1:\)La Data no proviene de dicha Población.

\hypertarget{prueba-de-kolmogorov-smirnov}{%
\subsubsection{Prueba de
Kolmogorov-Smirnov}\label{prueba-de-kolmogorov-smirnov}}

La prueba de Kolmogorov-Smirnov se utiliza para decidir si una muestra
proviene de una población con una distribución específica. Puede
aplicarse tanto para datos discretos (recuento) y continuos agrupados,
así como para las variables continuas. Se basa en una comparación entre
la función de distribución empírica (FDE) y la teórica definida como:

\[F(x)=\int_{\alpha}^{x}f(y;\theta)dy\]\\
donde \(f(y;\theta)\) es la función de densidad teórica y La FDE viene
definida como: dados los datos ordenados \(x_1, x_2, ..., x_n\) luego
\(F_n(x_i)=\frac{N_i}{n}\) donde \(N_i\) es el número de puntos inferior
a \(x_i\) (\(x_i\) están ordenados de menor a mayor valor). Esta es una
función de escalera que aumenta en 1/n en el valor de cada punto de
datos ordenados. El Estadístico de Contraste utilizado es:

\[D_n= max|F(x_i)-F_n (x_i ) |\]

Es decir, el extremo superior entre las diferencias de valor absoluto
entre FDE y la funcion de distribución teórica. La hipótesis con
respecto a la forma de distribución se rechaza \(H_0\) si el estadístico
de prueba, \(D_n\), es mayor que el valor crítico obtenido a partir de
una tabla, o lo que es lo mismo, si el \(p\) valor es menor que el nivel
de significación.

\hypertarget{prueba-de-anderson-darling}{%
\subsubsection{Prueba de
Anderson-Darling}\label{prueba-de-anderson-darling}}

Esta Prueba es similar a la prueba de Kolmogorov-Smirnov, pero tiene un
estadístico de contraste diferente para evaluar la cercanía o nivel de
representatividad de un modelo. La función de contraste es la siguiente:

\[A^2=n\int_{t}^{u}\frac{[F_n(x)-F_n^{*}]^2}{F^*(x)[1-F^*(x)]}f^*(x)dx\]

simplificando y resolviendo la integral se obtiene:

\[A^2=-nF^*(u)+n \sum_{j=1}^{k}[1-F_n(y_j)]^2\{ln[1-F^*(y_j)]-ln[1-F^*(y_j+1)]\}+ n\sum_{j=1}^{k}F_n(y_j)^2[lnF^*(y_j+1)-lnF^*(y_j)]\]

si \(u\) es un número finito entonces el valor crítico es más pequeño.

\hypertarget{prueba-de-la-chi-cuadrado}{%
\subsubsection{Prueba de la
Chi-Cuadrado}\label{prueba-de-la-chi-cuadrado}}

La prueba Chi-cuadrado \(\chi^2\) es la prueba de bondad de ajuste más
antigua que existe, formulada por \textbf{Karl Pearson (1900)}. Puede
ser pensada como una comparación formal de un histograma con la densidad
ajustada. Una característica atractiva de la prueba de bondad de ajuste
chi-cuadrado \(\chi^2\) es que se puede aplicar a cualquier distribución
univariante para la cual se pueda calcular la función de distribución
acumulativa, y aunque usualmente se aplica a los datos agrupados, es
decir, datos puestos en clases, no es realmente una restricción, ya que
para los datos no agrupados se puede simplemente calcular una tabla de
histograma o la frecuencia antes de generar la prueba de chi-cuadrado;
el valor de la prueba estadística de chi-cuadrado depende de cómo se
agrupen los datos.

Por otra parte, esta prueba se puede aplicar a distribuciones discretas
como continuas.

Por la forma de calcular la prueba de bondad de ajuste chi-cuadrado
\(\chi^2\), los datos se dividen en ``k'' contenedores y el estadístico
de prueba se define de esta manera:
\[\chi^2=\sum_{i=1}^{n}\frac{(O_i-E_i)^2}{E_i}\] Donde \(O_i\) es la
frecuencia observada para el intervalo \(i\), y \(E_i\) es la frecuencia
esperada para el intervalo \(i\). La frecuencia esperada se calcula por
la función de distribución acumulativa. Este estadístico se distribuye
como una variable aleatoria \(\chi^2\) con \(k-p-1\) grados de libertad
(p es el número de parámetros estimados por los datos de la muestra). La
hipótesis de que los datos provienen de una población con la
distribución especificada es aceptado si \(\chi^2\) es más baja que la
función de percentiles chi-cuadrado con \(k-p-1\) grados de libertad y
un nivel de significación de \(\alpha\). La prueba de chi-cuadrado es
muy sensible a la elección de los contenedores o intervalos.

\hypertarget{prueba-de-la-funcion-de-maxima-verosimilitud}{%
\subsubsection{Prueba de la Función de Máxima
Verosimilitud}\label{prueba-de-la-funcion-de-maxima-verosimilitud}}

El método de máxima verosimilitud se utiliza en el contexto de la
inferencia estadística para estimar los parámetros de una distribución.
Se tiene una variable aleatoria con una Función de Densidad conocida
\(f(x,\theta)\) que describe un carácter cuantitativo de la población.
Se debe estimar el vector de parámetros desconocidos y constante
\(\theta\) según los datos de muestreo: \(x_1,x_2,x_3,…,x_n\).

La estimación de máxima verosimilitud comienza con la expresión
matemática conocida como una función de probabilidad de los datos de la
muestra. En términos generales, la probabilidad de un conjunto de datos
es igual a la probabilidad de obtener ese conjunto particular de datos
dado el modelo elegido. Esta expresión contiene los parámetros
desconocidos. Esos valores del parámetro que maximicen la probabilidad
de la muestra se conocen como las estimación máximo verosímil (MLE). La
función de verosimilitud se define como:

\[L(x_1, x_2, x_3, ..., x_n, \theta)=\prod_{i=1}^{n}f(x_i, \theta)\]\\
El MLE consiste en encontrar aquel \(\theta\) que maximiza
\(L(x_1,x_2,x_3,…,x_n,\theta)\) o su función logarítmica. Se pueden
emplear métodos de análisis matemático (derivadas parciales e igualarlas
a cero) cuando la función de verosimilitud es bastante simple, pero muy
a menudo se optimiza \(L(x_1,x_2,x_3,…,x_n,\theta)\) usando métodos
iterativos. El MLE tiene varias propiedades estadísticas y ventajas. Por
ejemplo, en el caso de una distribución gamma, la función de
probabilidad es:

\[L(x_1, x_2, x_3, ..., x_n, \alpha, \lambda)=\prod_{i=1}^{n}f(x_i, \alpha, \lambda)\\ \prod_{i=1}^{n}\frac{\lambda^\alpha}{\Gamma(\alpha)}x_i^{\alpha-1}e^{-\alpha.x_i}=(\frac{\lambda^\alpha}{\Gamma(\alpha)})^n (\prod_{i=1}^{n}x_i)^{\alpha-1}e^{-\lambda\sum_{i=1}^{n} x_i} \]
y su logaritmo es:

\[log(L)=n\alpha log(\lambda)-n log(\Gamma(\alpha))+(\alpha-1)\sum_{i=1}^{n}log(x_i)-\lambda\sum_{i=1}^{n}x_i\]

\hypertarget{de-la-seleccion-del-modelo.}{%
\subsubsection{De la Selección del
Modelo.}\label{de-la-seleccion-del-modelo.}}

Todas las herramientas mostradas en los apartados anteriores tienen como
finalidad dar una idea del comportamiento de la variable en cuestión con
el objeto de hacer la \textbf{Selección del Modelo}. Para ello, se
desarrolló un procesos automatizado en el cual se hace una aproximación
de un Score o puntaje, dependiendo del grado de ajuste que tenga cada
modelo teórico definido a través de indicadores especiales, como los
resultados de las \textbf{Pruebas de Bondad de Ajuste} definidos en este
documento; en particular el mejor modelo será aquel que cumpla con las
siguientes características:

\begin{itemize}
\tightlist
\item
  El que tenga el menor valor en la prueba de
  \textbf{Kolmogorov-Smirnov}.\\
\item
  El que tenga el menor valor en la prueba de
  \textbf{Anderson-Darling}.\\
\item
  El que tenga el menor valor en la prueba de \(\chi^2\).\\
\item
  El mayor \(p\)-valor en la prueba de \(\chi^2\).\\
\item
  El Mayor valor de la \textbf{Función de Máxima Verosimilitud}.
\end{itemize}

A tráves de los siguientes ejemplos recorreremos la batería de Pruebas
Estadísticas con las Distribuciones de Probabilidades de Pérdidas
asociadas a los procesos de caracterización matemática soportado por la
\textbf{Teoría Matemática del Riesgo}.

\hypertarget{criterios-de-informacion-de-akaike-aic-y-bayesiano-bic.}{%
\subsubsection{Criterios de Información de Akaike (AIC) y Bayesiano
(BIC).}\label{criterios-de-informacion-de-akaike-aic-y-bayesiano-bic.}}

Ambos criterios estan basados en la penalización del Logarítmo de la
Verosimilitud. Considerando \(np\) el número de parámetros del modelo
ajustado, tenemos la forma:

\[-log\mathcal{L} + k.np\] luego con \(k=2\) es el AIC y con
\(k=log(n)\) es el BIC.

\hypertarget{inferencia-parametrica}{%
\section{Inferencia Paramétrica}\label{inferencia-parametrica}}

La Inferencia Paramétrica es el tratamiento con técnicas de estimación
de parámetros desconocidos dada una distribución selecionada. Asumimos
que \((x_1, ..., x_n)\) son realizaciones de una Variable aleatoria
\((X_1, ...,X_2)\) tal que \(X_i\) son independientes e identicamente
distribuidas y concuerdan con la variable aleatoria genérica \(X\). Esta
variable aleatoria \(X\) tiene una Función de Distribución
\(F(.;\theta)\) para \(\theta \in \Theta \subset \mathbb{R}^d\) donde
\(d\) es el número de parámetros a estimar. A continuación describiremos
un conjunto de metódos o técnicas que nos permiten obtener los
parámetrtos optimos de la distribución que representa los datos con
criterio estadístico.

El primero de los métodos es la estimación a través de la función máximo
verosímil, este método esta descrito en capítulo anterior.

\hypertarget{estimacion-por-coincidencia-de-cuantiles}{%
\subsection{Estimación por Coincidencia de
Cuantiles}\label{estimacion-por-coincidencia-de-cuantiles}}

Bajo este método la distribución paramétrica se ajusta haciendo
coincidir los Cuantiles de la distribución teórica seleccdionada con los
Cuantiles de la distribución empírica. esto es:

\[F^{-1}(p_k;\theta)=Q_{n,p_k}\] para \(k=1, ...,d\) and \(Q_{n,p_{k}}\)
son los cuantiles empíricos para probabilidades específicas. En algunas
ocasiones es posible conseguir una fórmula cerrada para esta condición,
por ejemplo si consideramos la distribución exponencial
\(\it{E}(\lambda)\) la función generadora de cuantiles es:

\[F^{-1}(p_k;\theta)=-\frac{\log(1-p)}{\lambda}\]

las solución de las \(d\) ecuaciones son objeto de una optimización
numérica la cual esta implementada en el paquete de R producto de este
trabajo.

\hypertarget{estimacion-por-coincidencia-de-momentos}{%
\subsection{Estimación por Coincidencia de
Momentos}\label{estimacion-por-coincidencia-de-momentos}}

La Estimación por Coincidencia de Momentos es comunmente utilizada para
ajustar distribuciones paramétricas. Esta metodología consiste en
encontrar el valor del parametro \(\theta\) que coincida con el primer
momento crudo de la distribución teórica (distribución paramétrica) con
el correspondiente momento de la distribución empírica. Esto es:

\[\mathbb{E}(X^{k}|\theta)=\frac{1}{n}\sum_{i=1}^{n}x_{i}^{k}\] para
\(k=1,...,d\), con \(d\) el número de parámetros a estimar y \(x_i\) la
\(n\)-ésima observación de la la variable \(X\). Para momentos de orden
mayores o iguales que 2 es más relevante con la coincidencia con los
momentos centrados que se definen como:

\[\mathbb{E}(X|\theta)=\bar{x}_{n}\]
\[\mathbb{E}((X-\mathbb{E}(X))^{k}|\theta)=m_k~~\forall k=2,...,d\]

donde \(m_k=\frac{1}{n}\sum_{i=1}^{n}(x_i-\bar{x}_n)^k\) es el
denominado momento central empírico.

En general, no existe las formulas cerradas para este estimador, por eso
hay que utilizar métodos numéricos para conseguirlo.

\hypertarget{maxima-bondad-de-ajuste}{%
\subsection{Máxima Bondad de Ajuste}\label{maxima-bondad-de-ajuste}}

El último método que utilizamos se denomina método de la Máxima Bondad
de Ajuste o método de la mínima distancia, en este trabajo se hizo foco
en la distancia de Cramér-von Mises, la misma observa la diferencia
entre la función distribución candidata \(F(x,\theta)\) y la empírica
\(F_n\), esta última dada como el porcentaje de observaciones siguientes
de \(x\): \(F_n(x)=\sum_{i=1}^{n}1_{x_i\leq x}\) la Distancia de
Cramér-von Mises está definida como:

\[D(\theta)=\int_{-\infty}^{\infty}(F_n(x)-F(x;\theta))^2dx\]

y en términos practicos es estimado con la siguiente formula

\[\hat{D}(\theta)=\frac{1}{12n}+\sum_{i=1}^{n}\left(F(x_i ;\theta)-\frac{2i-1}{2n}\right)^2\]
finalmente el método consiste en encontrar el valor de \(\theta\) que
minimice \(\hat{D}(\theta)\), como en el caso anterior no existen
formulas cerradas para el argumento \(min\{\hat{D}(\theta)\}\) por lo
que se utilizan métodos numéricos.

\hypertarget{valor-en-riesgo-var}{%
\section{Valor en Riesgo (VaR)}\label{valor-en-riesgo-var}}

La probabilidad basada en modelos provee una descripción de la
exposición al riesgo, el nivel de exposición de riesgo es frecuentemente
descrito por un número o un pequeño conjunto de ellos; estos números son
funciones (medidas) sobre el modelo elegido que muy frecuentemente son
llamados \textbf{Indicadores Claves de Riesgo}. Estos indican el grado
de materialización de un aspecto del riesgo en términos de las
definición de un evento a caracterizar. En particular, se define el
\textbf{VaR} o Valor a Riesgo como el percentil de la Distribución
Agregada de Riesgo (Función de Distribución Acumulada), cuya
interpretación es observada como \textbf{la posibilidad de obtener un
resultado adverso}; este puede ser expresado a través del \textbf{VaR}
con un particular nivel de probabilidad. El \textbf{VaR} en el área
financiera suele ser utilizado para la determinación de un Monto o Nivel
de Capital requerido para soportar dichos resultados adversos.

Adicionalmente, definimos el Tail-Value-at-Risk \textbf{TVaR} o
\textbf{VaR de Cola}, utilizada en varias áreas y nombrada de distintas
maneras, entre las más frecuentes: Conditional-Value-at-Risk
\textbf{CVaR} o \textbf{VaR Condicional}, Conditional Tail Expectation
\textbf{CTE} y Expected Shortfall \textbf{ES} o Expectativa a Corto
Plazo.

El \textbf{VaR} o Valor en Riesgo ha resultado ser el estándar de
medición para evaluar la exposición de Riesgo. En términos generales, el
\textbf{VaR} es el monto de capital requerido para asegurar con cierto
grado de certeza que la institución en cuestión no resulte técnicamente
insolvente. Este grado de certeza es arbitrario y por lo general se
pasea entre el 95\% y el 99\%.

En esta oportunidad se considera la Variable Aleatoria \(X_j\) que
representa las posibles pérdidas asociadas al Riesgo de Liquidez para
una cuenta o partida en particular; luego, el total de los agregados
diarios es la suma de todas las pérdidas, esto es:

\[X=X_1+X_2+...+X_n\]

Además, se enuncia un conjunto de propiedades que garantizan la
coherencia de las medidas de riesgo.

Definición:

Una \textbf{Medida Coherente de Riesgo} \(\rho(X)\) es cualquier función
que cumpla con las siguientes propiedades:

Sea \(X\) y \(Y\) 2 Variables Aleatorias de Pérdida. Entonces:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  \textbf{Subaditividad}: \(\rho(X+Y) \leq \rho(X)+\rho(Y)\).\\
\item
  \textbf{Monotonía}: sí \(X \leq Y\) para todos los posibles resultados
  entonces \(\rho(X)\leq\rho(Y)\).\\
\item
  \textbf{Homogeneidad Positiva}: para cualquier constante positiva
  \(c\), \(\rho(cX)=c\rho(X)\).\\
\item
  \textbf{Invarianza en Traslación}: para cualquier constante positiva
  \(c\), \(\rho(X+c)=\rho(X)+c\).
\end{enumerate}

\hypertarget{principio-de-la-desviacion-estandar.}{%
\subsection{\texorpdfstring{\textbf{Principio de la Desviación
Estandar.}}{Principio de la Desviación Estandar.}}\label{principio-de-la-desviacion-estandar.}}

El Principio de la Desviación Estándar es una medida de incertidumbre de
una Distribución de Probabilidad. Si se tiene una Distribución de
Probabilidad de Pérdida con media \(\mu\) y desviación estándar
\(\sigma\), la cantidad \(\mu+k\sigma\) donde \(k\in \mathbb{R}\) es una
medida de riesgo, el coeficiente \(k\) es seleccionado dependiendo de la
\textbf{Asimetría y Curtósis} de la Distribución en cuestión; en esta
definición se encuentra la clave detrás del \textbf{VaR}.

ahora definiremos matemáticamente el \textbf{VaR} y veremos su
formulación asociado con algunas Distribuciones de Probabilidad
notables.

Supongamos que el valor de un portafolio hoy es denotado \(V_0\) y en el
tiempo \(t\), es \(V_t\). Se define que la distribución de pérdida será
igual a la distribución de las diferencias

\[X_t = V_0 - V_t\]

Nótese que la variable está definida del punto de vista de la pérdida,
lo que implica que un valor negativo en esta variable significa una
ganancia o lucro probable.

Siendo \(X\) una Variable Aleatoria de Pérdida, el Valor en Riesgo de
\(X\) al nivel de certeza del \(p\)\% se denota \(VaR_{p}(X)\) y es el
\(p\) Percentil de la Distribución de Pérdida Asociado a \(X\) o lo que
es lo mismo del punto de vista analítico

\[\mathbb{P}(X>x_p)=p\]

Alternativamente, se puede usar la función de probabilidad acumulada de
\(X\), se denota \(F_X\), donde el VaR de nivel de confianza \(p\) es

\[F_{X}^{-1}(1-p)\]

En la práctica de la formulación de riesgo del sector bancario es común
encontrar el VaR definido en términos de \(1-p\), por ejemplo 95\% de
confianza, 99\% de confianza, etc..

El cálculo del VaR requiere la cuantificación de la distribución de los
retornos. Uno de los enfoques es asumir que los retornos de un Activo (o
Pasivo) en particular sigue una distribución de probabilidad específica,
por ejemplo la distribución normal este acercamiento es el denominado
como " \textbf{Paramétrico} ", asímismo, requiere asumir parámetros
necesarios que caracterizan los datos dentro de la distribución.

Otro de los acercamientos asume el cálculo a través de la proyección de
la desviación estándar de los retornos empíricos para ajustar la
volatilidad del indicador a través de la historia del mismo, por eso
dicho acercamiento se denomina " \textbf{Histórico} ``, una de las
desventajas de este método es que se necesita información''suficiente",
para poder ajustar o sintonizar razonablemente dicha estimación. es de
notar que detrás de este concepto se asume la misma ponderación o
importancia al peso de todos los datos evaluados es decir la ponderación
de se da de manera uniforme.

\emph{La gráfica corresponde a el cálculo de la volatilidad asociada al
VaR de los retornos de las acciones de Conoco Phillips desde el
01-07-2007 hasta el 31-12 2010, por el método Histórico, en la misma se
observa que dónde mayor número de períodos de la volatilidad fueron
tomados en cuenta (\textbf{RollSD52}), la volatilidad estimada resultó
más sintonizada o convergente.}

Sin embargo, el método antes mencionado podría no sustentar las
estimaciones en economías inflacionarias porque perdería vigencia
rápidamente ya que obviamente los datos más antiguos sufrirían un
devaluación que no estaría considerada en el modelo. Esta pertinente
observación da paso a otro enfoque del cálculo y pronóstico del VaR a
través de la suavización exponencial utilizando un modelos de serie de
tiempo \textbf{EWMA} Exponentially Weighted Moving Average o Promedios
Móviles Exponencialmente Pesados, cuya formulación de la volatilidad
viene dado por:

\[\hat{\sigma}_n^2 = \lambda \hat{\sigma}_{n-1}^2 + (1 - \lambda) u_{n-1}^2\]

dónde:

\(\hat{\sigma}_{n-1}^2\) es la varianza estimada en el período \(n-1\)

\(u_{n-1}^2\) es el cuadrado de los retornos del período \(n-1\)

\(\lambda\) es una constante entre 0 y 1.

la idea de la selección del modelo exponencial es seleccionar la
constante \(\lambda\) que minimice el error cuadrático medio entre la
volatilidad estimada y la volatilidad observada.

Siguiendo este orden de ideas también podemos estimar la volatilidad
asociada al VaR estableciendo un modelo de series de tiempo general
donde la varianza del modelo sea dinámica (no necesariamente
exponencial) pero que cuya variabilidad se pueda expresar en función del
tiempo. dicho modelo es denominado \textbf{GARCH} por sus siglas en
inglés, son los Autoregresivos de Heterocedasticidad Condicional
Generalizados, presentados por Bollerslev en 1986. Este modelo de serie
de tiempo posee 2 parámetros, GARCH(p,q), el mismo calcula
\(\sigma_n^2\) desde la más reciente \(p\) observación de \(u^2\) y la
más reciente \(q\) estimación de \(\sigma_n^2\). Luego, el GARCH(1,1) en
concordancia con lo mencionado anteriormente se refiere a la más
reciente observación de \(u^2\) y la más reciente estimación de
\(\sigma_n^2\), este modelo es muy usado para la estimación del VaR. La
ecuación del modelo GARCH(1,1) es:

\[\sigma_n^2 = \gamma V_L + \alpha u_{n-1}^2 + \beta \sigma_{n-1}^2\]

dónde:

\(\gamma\) es el peso asignado a \(V_L\)

\(V_L\) es el promedio de la varianza en el largo plazo

\(\alpha\) es el peso asignado a \(u_{n-1}^2\)

\(u_{n-1}\) es el cuadrado de los retornos en el período \(n-1\)

\(\beta\) es el peso asignado a \(\sigma_{n-1}^2\)

\(\sigma_{n-1}^2\) es la varianza estimada en el período \(n-1\)

Nótese que:

\[\gamma + \alpha + \beta = 1\]

observese que el modelo discutido en el apartado anterior es un caso
particular de este modelo generalizado el mismo se puede escribir como
GARCH(1,1) donde \(\gamma=0\), \(\alpha= 1 - \lambda\) y
\(\beta = \lambda\)

Un aspecto muy importante de cálculo paramétrico del VaR es su
formulación asociada a la distribución de probabilidad que describa a
los retornos ya que dado los parámetros se pueden conseguir su inversa
para realizar un proceso de simulación histórica. Aquí presentamos
algunas de las más comunes.

\hypertarget{var-normal}{%
\subsubsection{\texorpdfstring{\textbf{VaR
Normal:}}{VaR Normal:}}\label{var-normal}}

Para el cálculo y la determinación del VaR cuya \textbf{Bondad de
Ajuste} de como resultado la distribución normal tenemos que :

\(X \approx N(0,1)\)

Cuya función de densidad es

\[f(x) = \frac{1}{\sqrt{2 \pi \sigma}} e^-\frac{(x - \mu)^2}{(2 \sigma^2)}\]

donde;

\(\mu\) es igual a la media de la distribución y\\
\(\sigma\) es la desviación típica

luego tenemos la función de distribución acumulada

\[F_{X}(x) = \phi(x) = \mathbb{P}(X \leq x) = \frac{1}{\sqrt{2 \pi \sigma}} = \int_{-\infty}^{x}e^{\frac{-x^2}{2}}\]

entonces utilizamos el principio de la desviación standart

\[Y = \mu + \sigma X\]

tenemos entonces que \(VaR_{p}(X)\) es el número tal que:

\[
\begin{array}{rl}
&\displaystyle \mathbb{P}(Y \leq VaR_{p}(X)) = p\\
&\displaystyle \Rightarrow \mathbb{P}(\mu + \sigma X \leq VaR_{p}(X)) = p\\
&\displaystyle \Rightarrow \mathbb{P}(\mu - \mu + \sigma X \leq VaR_{p}(X)- \mu) = p\\
&\displaystyle \Rightarrow \mathbb{P}(\cancel{\mu} - \cancel{\mu} + \sigma X \leq VaR_{p}(X)- \mu) = p\\
&\displaystyle \Rightarrow \mathbb{P}(\sigma X \sigma^{-1} \leq (VaR_{p}(X) -\mu) * \sigma^{-1}) = p\\
&\displaystyle \Rightarrow \mathbb{P}(\cancel{\sigma} X \cancel{\sigma^{-1}} \leq (VaR_{p}(X) -\mu) * \sigma^{-1}) = p\\
&\displaystyle \Rightarrow \mathbb{P}(X \leq (VaR_{p}(X) -\mu) * \sigma^{-1}) = p\\
&\displaystyle \Rightarrow \phi((VaR_{p}(X) -\mu) * \sigma^{-1}) = p\\
&\displaystyle \Rightarrow (VaR_{p}(X) -\mu) * \sigma^{-1} = \phi^{-1}(p)\\
&\displaystyle \Rightarrow \sigma * {(VaR_{p}(X) -\mu) * \sigma^{-1}} = \sigma * \phi^{-1}(p)\\
&\displaystyle \Rightarrow \not{\sigma} * {(VaR_{p}(X) -\mu) * \not{\sigma^{-1}}} = \sigma * \phi^{-1}(p)\\
&\displaystyle \Rightarrow VaR_{p}(X) -\mu = \sigma * \phi^{-1}(p)\\
&\displaystyle \Rightarrow VaR_{p}(X) -\mu + \mu = \mu + \sigma * \phi^{-1}(p)\\
&\displaystyle \Rightarrow VaR_{p}(X) -\cancel{\mu} + \cancel{\mu} = \mu + \sigma * \phi^{-1}(p)\\
&\displaystyle \Rightarrow VaR_{p}(X) = \mu + \sigma * \phi^{-1}(p)
\end{array}\]

lo que resulta:

\[VaR_p(x)=\mu+\sigma* \phi^{-1}(p)\]

\hypertarget{var-cauchy}{%
\subsubsection{\texorpdfstring{\textbf{VaR
Cauchy:}}{VaR Cauchy:}}\label{var-cauchy}}

Dado que la \textbf{Bondad de Ajuste} de como resultado la distribuyción
Cauchy tenemos entonces su función de densidad viene dada por:

\[f(x)= \frac{1}{\pi(1+x^2)}\]

y su función de distribución

\[\begin{array}{rl}
F_{X}(x) &=\int_{-\infty}^{x} \frac{1}{\pi(1+t^2)}dt\\
&\displaystyle =\frac{1}{\pi} \left[ \arctan(t) \right] \big |_{t=-\infty}^{t=x}\\
&\displaystyle =\frac{1}{\not{\pi}} \left[ \frac{\not{\pi}}{2}+ \arctan(x)\right]\\
&\displaystyle =\left[ \frac{1}{2} + \frac{1}{\pi}\arctan(x)\right]\\
F_{X}(x) &=\left[ \frac{1}{2} + \frac{1}{\pi}\arctan(x)\right]
\end{array}\]

luego asumimos los siguientes parámetros:

\(\mu\): como parámetro de locación. \(\sigma\) como parámetro de
escala.

para determinar el VaR aplicamos el principio de la desviación standart

\[\begin{array}{rl}  
&\displaystyle  \mathbb{P}[\mu + \sigma X \leq VaR_{p}(x)] = p\\
&\displaystyle  \Rightarrow \mathbb{P}[X \leq \frac{VaR_{p}(x)- \mu}{\sigma}] = p\\
&\displaystyle  \Rightarrow F_{X}(\frac{VaR_{p}(x)- \mu}{\sigma}) = p\\
&\displaystyle  \Rightarrow \frac{1}{2} + \frac{1}{\pi}\arctan\left[\frac{VaR_{p}(x) - \mu}{\sigma}\right] = p\\
&\displaystyle  \Rightarrow \arctan\left[\frac{VaR_{p}(x) - \mu}{\sigma}\right] = \pi(p-\frac{1}{2})\\
&\displaystyle  \Rightarrow \left[\frac{VaR_{p}(x) - \mu}{\sigma}\right] = \tan\left[\pi(p-\frac{1}{2})\right]\\
&\displaystyle  \Rightarrow VaR_p(x)=\mu+\sigma*\tan\left[\pi\left(p-\frac{1}{2}\right)\right]
\end{array}\]

cuyo resultado es:

\[VaR_p(x)=\mu+\sigma*\tan\left[\pi\left(p-\frac{1}{2}\right)\right]\]

\hypertarget{var-lognormal}{%
\subsubsection{\texorpdfstring{\textbf{VaR
Lognormal:}}{VaR Lognormal:}}\label{var-lognormal}}

Dado que la \textbf{Bondad de Ajuste} de como resultado la distribución
Lognormal tenemos entonces su función de densidad viene dada por:

\[f(X)=\frac{1}{\sigma X} \psi(\frac{\log(X)-\mu}{\sigma})\]

y su función de distribución:

\[F(X)=\phi(\frac{\log(X)-\mu}{\sigma})\]

luego aplicando el principio de la desviación standart y la definición
de Valor en Riesgo tenemos que:

\[Y = \mu + \sigma \log(X)\]

\[\begin{array}{rl}  
&\displaystyle \mathbb{P}[Y \leq VaR(\log(X))_p]=p\\
&\displaystyle \Rightarrow \mathbb{P}[\mu + \sigma \log(X) \leq VaR_p(\log(X))] = p\\
&\displaystyle \Rightarrow \mathbb{P}[\log(X) \leq \frac{VaR_{p}(\log(X))- \mu}{\sigma}] = p\\
&\displaystyle \Rightarrow F_X(\frac{VaR_{p}(\log(X))- \mu}{\sigma}) = p\\
&\displaystyle \Rightarrow \frac{VaR_{p}(\log(X))- \mu}{\sigma} = F_X^{-1}(p)=\phi^{-1}(p)\\
&\displaystyle \Rightarrow VaR_{p}(\log(X))=\phi^{-1}(p) \sigma + \mu\\
&\displaystyle \Rightarrow VaR_{p}(X)=e^{\phi^{-1}(p) \sigma + \mu}
\end{array}\]

lo que resulta

\[VaR_{p}(X)=e^{\phi^{-1}(p) \sigma + \mu}\]

\hypertarget{var-exponencial}{%
\subsubsection{\texorpdfstring{\textbf{VaR
Exponencial:}}{VaR Exponencial:}}\label{var-exponencial}}

Sea el VaR perteneciente a una población que se distribuye exponencial
tenemos función de densidad dada por:

\[f(X)= \lambda e^{-\lambda X}\]

y su función de Distribución:

\[F_X(X)= 1-e^{-\lambda X}\]

luego aplicando el principio de la Desviación Standart tenemos que

\[Y = \mu + \sigma X\]

\(\mu\): como parámetro de locación. \(\sigma\) como parámetro de
escala.

por características matemáticas de la distribución exponencial el
parámetro de escala coincide con la unidad cuando el parámetro de
locación es igual a 0. por tanto:

\[\begin{array}{rl}  
&\displaystyle \mathbb{P}[Y \leq VaR(X)_p]=p\\
&\displaystyle \Rightarrow \mathbb{P}[\mu + \sigma X \leq VaR_p(X)] = p\\
&\displaystyle \Rightarrow \mathbb{P}[0 + 1* X \leq VaR_p(X)] = p\\
&\displaystyle \Rightarrow F_X(VaR_{p}(X)) = p\\
&\displaystyle \Rightarrow 1- e^{-\lambda VaR_{p}(X)}=p\\
&\displaystyle \Rightarrow e^{-\lambda VaR_{p}(X)}= 1-p\\
&\displaystyle \Rightarrow -\lambda VaR_{p}(X)= \log(1-p)\\
&\displaystyle \Rightarrow VaR_{p}(X)= -\frac{1}{\lambda}\log(1-p)
\end{array}\]

lo que resulta:

\[VaR_{p}(X)= -\frac{1}{\lambda}\log(1-p)\]

\hypertarget{var-uniforme}{%
\subsubsection{\texorpdfstring{\textbf{VaR
Uniforme:}}{VaR Uniforme:}}\label{var-uniforme}}

función de densidad

\[f(X)= \frac{1}{b-a}\]

Función de Distribución

\[F(X)= \frac{X-a}{b-a}\]

aplicando la definición del VaR

\[\begin{array}{rl}  
&\displaystyle \mathbb{P}[Y \leq VaR(X)_p]=p\\
&\displaystyle \Rightarrow \mathbb{P}[\mu + \sigma X \leq VaR_p(X)] = p\\
&\displaystyle \Rightarrow \mathbb{P}[0 + 1* X \leq VaR_p(X)] = p\\
&\displaystyle \Rightarrow F_X(VaR_{p}(X)) = p\\
&\displaystyle \Rightarrow \frac{VaR_{p}(X)-a}{b-a}=p\\
&\displaystyle \Rightarrow VaR_{p}(X)-a=p(b-a)\\
&\displaystyle \Rightarrow VaR_{p}(X)=a+p(b-a)
\end{array}\]

por tanto el VaR Uniforme es :

\[VaR_{p}(X)=a+p(b-a)\]

\hypertarget{var-weibull}{%
\subsubsection{\texorpdfstring{\textbf{VaR
Weibull:}}{VaR Weibull:}}\label{var-weibull}}

función de densidad

\[f(X)= \frac{\alpha x^{\alpha-1}}{\sigma^{\alpha}}e^{-(x/\sigma)^\alpha}\]

Función de Distribución

\[F(X)= 1-e^{-(x/\sigma)^\alpha}\]

aplicando la definición del VaR

\[\begin{array}{rl}  
&\displaystyle \mathbb{P}[Y \leq VaR_{p}(X)]=p\\
&\displaystyle \Rightarrow \mathbb{P}[\mu + \sigma X \leq VaR_p(X)] = p\\
&\displaystyle \Rightarrow \mathbb{P}[0 + 1* X \leq VaR_p(X)] = p\\
&\displaystyle \Rightarrow F_X(VaR_{p}(X)) = p\\
&\displaystyle \Rightarrow 1-e^{-(VaR_{p}(X)/\sigma)^\alpha}=p\\
&\displaystyle \Rightarrow e^{-(VaR_{p}(X)/\sigma)^\alpha}=1-p\\
&\displaystyle \Rightarrow -(VaR_{p}(X)/\sigma)^\alpha=\log(1-p)\\
&\displaystyle \Rightarrow (VaR_{p}(X)/\sigma)^\alpha=-\log(1-p)\\
&\displaystyle \Rightarrow (VaR_{p}(X)/\sigma)=[-\log(1-p)]^{1/\alpha}\\
&\displaystyle \Rightarrow VaR_{p}(X)=\sigma [-\log(1-p)]^{1/\alpha}\\
\end{array}\]

por tanto el VaR Weibull es:

\[VaR_{p}(X)=\sigma [-\log(1-p)]^{1/\alpha}\]

adicionalmente mostramos la formulación del \textbf{TVaR}

\hypertarget{var-de-cola-tvar}{%
\subsection{VaR de Cola (TVaR)}\label{var-de-cola-tvar}}

Sea \(X\) una Variable Aleatoria de Pérdida, el Tail-Value-at-Risk
\textbf{TVaR} de \(X\) al nivel de certeza del \(p\)\% se denota
\(TVaR_{p}(X)\) y es la pérdida esperada dado que la misma excede el
\(p\) Percentil de la Distribución de Pérdida Asociado a \(X\). El mismo
se puede escribir:

\[TVaR_p(X)=\mathbb{E}(X|X>x_p)=\frac{\int_{x_p}^{\infty}xdF(x)}{1-F(x_p)}\]
\[TVaR_p(X)=\frac{\int_{x_p}^{\infty}xf(x)dx}{1-F(x_p)}=\frac{\int_{1}^{p}VaR_u(X)du}{1-p}\]

De esta manera se obtiene la forma genérica del \textbf{TVaR}. A
continuación se presenta la formulación por cada tipo de Distribución de
Probabilidad.

La forma de obtener el TVaR depende de la familia de distribución al que
pertenezca la población evaluada que es la misma distribución a través
de la cual es asociado el cálculo del VaR.

Una de las formas viene dada si dicha distribución pertenece a la
Familia de \textbf{Distribuciones Elípticas}, las mismas están definidas
como el conjunto de distribuciones cuyo contorno de sus versiones
multivariantes tiene forma de elipse. La versión univariante corresponde
a la marginal de estas. Por ejemplo, la Normal y la T Student son
elípticas, en cambio la distribución exponencial no lo es.

Una de las características deseables de esta familia de distribuciones
probabilísticas es que tiene soporte real, es decir tienen soporte tanto
positivo como negativo, a pesar que las distribuciones que poseen esta
caraterística no son usadas frecuentemente en modelaje de pérdidas,
podrían ser usadas en el modelaje y caracterización de variables
aleatorias tales como la tasa de retorno, tasas de rendimiento ya que
toman valores positivos y negativos además las mismas también son
utilizadas en el campo de las finanzas y de la administración de riesgo.

Por definición la función de densidad puede ser escrita de la siguiente
manera:

\[f(x)=\frac{c}{\sigma}g\left[\frac{1}{2}\left(\frac{x-\mu}{\sigma}\right)^2\right]\]

donde:

\(g(x)\) es una función tal que \(\int_{0}^{\infty}g(x)dx < \infty\)\\
\(G(x)=c\int_{0}^{x}g(y)dy\) y \(\bar{G}(x)=G(\infty)-G(x)\)\\
\(F(x)=\int_{-\infty}^{x}f(y)dy\) y \(\bar{F}(x)=1-F(x)\)

\hypertarget{teorema}{%
\subsubsection{Teorema}\label{teorema}}

Considere cualquier distribución elíptica univariante, con media y
varianza finita. Entonces el \(TVaR\) a nivel de confianza \(p\) del
\(VaR_p(X)\), donde \(p > 1/2\) se puede escribir como:

\[TVaR_p(X)=\mu + \lambda \sigma^2\]

donde:

\[\lambda=\frac{\frac{1}{\sigma}\bar{G} \left[ \frac{1}{2} \left(\frac{VaR_p(x)-\mu}{\sigma}\right)^2\right]}{\bar{F}(VaR_p(x))}\]

\hypertarget{demostracion}{%
\paragraph{Demostración}\label{demostracion}}

Por la definición de \(TVaR\)

\[\begin{array}{rl} 
 TVaR_p(X) &\displaystyle =\frac{1}{\bar{F}(VaR_p(x))} \int_{VaR_p(x)}^{\infty}x.f(x) dx\\
 &\displaystyle =\frac{1}{\bar{F}(VaR_p(x))} \int_{VaR_p(x)}^{\infty}x.\frac{c}{\sigma}g\left[\frac{1}{2}\left(\frac{x-\mu}{\sigma}\right)^2\right]dx\\
\end{array}\]

hacemos \(z=(VaR_p(x)- \mu)/\sigma\)

\[\begin{array}{rl} 
TVaR_p(X) &\displaystyle =\frac{1}{\bar{F}(VaR_p(x))} \int_{\frac{VaR_p(x)-\mu}{\sigma}}^{\infty}(\mu + \sigma z).c.g\left(\frac{1}{2}z^2\right)dz dx\\
&\displaystyle =\mu + \frac{cq}{\bar{F}(VaR_p(x))}\int_{\frac{VaR_p(x)-\mu}{\sigma}}^{\infty}z.g\left((\frac{1}{2}z^2\right)dz\\  
&\displaystyle = \mu + \lambda \sigma^2
\end{array}\]

devolviendo el cambio y agrupando convenientemente

\[\begin{array}{rl}
\lambda &\displaystyle =\frac{c}{\sigma \bar{F}(VaR_p(x))} \int_{\frac{1}{2}(\frac{VaR_p(x)-\mu}{\sigma})^2}^{\infty} g(u) du\\
&\displaystyle =\frac{1}{\sigma \bar{F}(VaR_p(x))}\bar{G} \left[\frac{1}{2} \left(\frac{VaR_p(x)-\mu}{\sigma}\right)^2\right]
\end{array}\]

\hypertarget{tvar-logistica}{%
\subsubsection{\texorpdfstring{\textbf{TVaR
Logistica:}}{TVaR Logistica:}}\label{tvar-logistica}}

La distribución logística tiene una densidad de la forma:

\[f(x)=\frac{c}{\sigma}g\left[\frac{1}{2}\left(\frac{x-\mu}{\sigma}\right)^2\right]\]

donde

\[g(u)= \frac{\exp(-\mu)}{(1+ \exp(-\mu))^2}\]

y \(c=1/2\). Entonces

\[\begin{array}{rl}
G(x) &\displaystyle=\frac{1}{2}\int_{0}^{x}g(u)du\\
&\displaystyle=\frac{1}{2}\int_{0}^{x}\frac{\exp(-\mu)}{(1+ \exp(-\mu))^2}du\\
&\displaystyle=\frac{1}{2}\left[\frac{1}{1+\exp(-x)-\frac{1}{2}}\right]
\end{array}\]

\[\begin{array}{rl}
\frac{1}{\sigma} \bar{G}\left[\frac{1}{2}\left(\frac{VaR_p(x)-\mu}{\sigma}\right)^2\right] &\displaystyle= \frac{1}{2 \sigma} \left[1-\frac{1}{1+ \exp\left[-\frac{1}{2}\left(\frac{VaR_p(x)-\mu}{\sigma}\right)^2\right]}\right]\\
&\displaystyle
= \frac{1}{2 \sigma}\frac{\exp\left[-\frac{1}{2} \left(\frac{VaR_p(x)-\mu}{\sigma}\right)^2\right]}{1+ \exp \left[-\frac{1}{2} \left(\frac{VaR_p(x)-\mu}{\sigma}\right)^2\right]}\\
&\displaystyle= \frac{1}{2} \frac{ \frac{1}{\sigma}\phi\left(\frac{VaR_p(x)-\mu}{\sigma}\right)}{\frac{1}{\sqrt{2\pi}+\phi\left(\frac{VaR_p(x)-\mu}{\sigma}\right)}}
\end{array}\]

luego aplicando la solución de las distribuciones elípticas para el
cáculo del TVaR tenemos que:

\[TVaR_p(x)= \mu + \lambda \sigma^2\]

donde

\[h=\frac{1}{\sigma \bar{F}(VaR_p(x))}\bar{G} \left[\frac{1}{2} \left(\frac{VaR_p(x)-\mu}{\sigma}\right)^2\right]\]

lo que resulta:

\[TVaR_p(x)= \mu + \frac{1}{2} \left[\frac{ \frac{1}{\sigma}\phi\left(\frac{VaR_p(x)-\mu}{\sigma}\right)}{\frac{1}{\sqrt{2\pi}+\phi\left(\frac{VaR_p(x)-\mu}{\sigma}\right)}}\frac{ \frac{1}{\sigma}\phi\left(\frac{VaR_p(x)-\mu}{\sigma}\right)}{\bar{F}(\frac{VaR_p(x)-\mu}{\sigma})} \right]\]

Otra forma de calcular el TVaR consiste en utilizar una generalización
de la distribución normal, pero solo extendiendolo a las variables
aleatorias que tenga soporte positivo unicamente. Dicha generalización
considera la familia exponencial cuyos modelos de dispersión son
\textbf{Familia Exponencial de Dispersión Aditiva} y \textbf{Familia
Exponencial de Dispersión Reproductiva}, ( \textbf{AEDF} ) y (
\textbf{REDF} ) por sus siglas en inglés. la definición de ambas
familias de distribuciones de probabilidad es la misma con excepción del
rol que juega el inverso del parámetro de dispersión \(\lambda\).

\hypertarget{definicion}{%
\subsubsection{Definición}\label{definicion}}

Una Variable Aleatoria X tiene una distribución que viene de una
\textbf{Familia Exponencial de Dispersión Aditiva} y \textbf{Familia
Exponencial de Dispersión Reproductiva} respectivamente, si su función
de densidad se puede escribir en términos de los parametros \(\theta\) y
\(\lambda\) con la siguiente forma:

AEDF \[f(x;\theta, \lambda)=e^{\theta x-\lambda k(\theta)}q(x;\lambda)\]

REDF
\[f(x;\theta, \lambda)=e^{\lambda[\theta x- k(\theta)]}q(x;\lambda)\]

La media y la varianza de estas distribuciones son:

Media:

AEDF \(\mu = \lambda k'(\theta)\) REDF \(\mu=k'(\theta)\)

Varianza:

AEDF \(Var(X) = \lambda k''(\theta)=k''(\theta)/\sigma^2\) REDF
\(Var(X) = k''(\theta)/\lambda=k''(\theta)\sigma^2\)

donde

\(1/\lambda = \sigma^2\) es llamado el parámetro de dispersión.

\hypertarget{teorema-1}{%
\subsubsection{Teorema}\label{teorema-1}}

sea \(X\) una variable aleatoria cuya distribución proviene de una
\textbf{AEDF}. entonces \(TVaR_p(X)\) se puede escribir como:

\[TVaR_p(X)=\mu + h\]

donde

\(h=\frac{\partial}{\partial \theta}\ln[\bar{F}(VaR_p;\theta,\lambda)]\)

\hypertarget{demostracion-1}{%
\paragraph{Demostración}\label{demostracion-1}}

\[\begin{array}{rl}
\frac{\partial}{\partial \theta}\ln[\bar{F}(VaR_p;\theta,\lambda)] &\displaystyle= \frac{1}{\bar{F}(VaR_p(x);\theta,\lambda)} \int_{VaR_p(x)}^{\infty} \frac{\partial}{\partial \theta}e^{[\theta x - \lambda k(\theta)]}q(x;\lambda)dx\\
&\displaystyle= \frac{1}{\bar{F}(VaR_p(x);\theta,\lambda)} \int_{VaR_p(x)}^{\infty} \left[[x- \lambda k'(\theta)]e^{\lambda[\theta x - k(\theta)]}q(x;\lambda)\right]dx\\
&\displaystyle= \frac{1}{\bar{F}(VaR_p(x);\theta,\lambda)} \int_{VaR_p(x)}^{\infty} xf(x;\theta,\lambda)dx - \lambda k'(\theta)\\
\frac{\partial}{\partial \theta}\ln[\bar{F}(VaR_p;\theta,\lambda)] &\displaystyle= TVaR_p(x) - \mu
\end{array}\]

\hypertarget{tvar-gamma}{%
\subsubsection{\texorpdfstring{\textbf{TVaR
Gamma:}}{TVaR Gamma:}}\label{tvar-gamma}}

Se puede demostrar que la distribución Gamma pertenece a la
\textbf{Familia Exponencial de Dispersión Aditiva} si observamos la
densidad tenemos

\[f(x)=\frac{1}{x \Gamma(\alpha)} \left(\frac{x}{\beta}\right)^{\alpha} \exp \left(-\frac{x}{\beta}\right)\]\\
donde

\(\theta=-\frac{1}{\beta}\) \(\lambda=\alpha\)\\
\(k(\theta) = -\ln(-\theta)\)
\(q(x;\lambda)=\frac{x^{\alpha-1}}{\Gamma(\alpha)}\)

lo que satisface las condiciones del teorema de AEDF.

luego el \(TVaR_p(x)\) se calcula como:

\[TVaR_p(X)= \mu + h\]

donde

\[\begin{array}{rl}
h &\displaystyle=\frac{\partial}{\partial \theta}\ln[\bar{F}(VaR_p;\theta,\lambda)]\\
&\displaystyle= \frac{1}{\bar{F}(VaR_p;\theta,\lambda)} \frac{\partial}{\partial \theta} \int_{VaR_p(x)}^{\infty} \frac{x^{\lambda-1}}{\Gamma(\lambda)} e^{[\theta x -\lambda \ln(-\theta)]}dx\\
&\displaystyle= \frac{1}{\bar{F}(VaR_p;\theta,\lambda)}  \int_{VaR_p(x)}^{\infty} \frac{x^{\lambda-1}}{\Gamma(\lambda)} \frac{\partial}{\partial \theta}e^{[\theta x -\lambda \ln(-\theta)]}dx\\
&\displaystyle= \frac{1}{\bar{F}(VaR_p;\theta,\lambda)}  \int_{VaR_p(x)}^{\infty} \frac{x^{\lambda-1}}{\Gamma(\lambda)} \left(x + \frac{\lambda}{\theta}\right)e^[\theta x -\lambda \ln(-\theta)]dx\\
&\displaystyle= \frac{1}{\bar{F}(VaR_p;\theta,\lambda)} \left[-\frac{1}{\theta} \frac{\Gamma(\lambda + 1)}{\Gamma(\lambda)} \int_{VaR_p(x)}^{\infty} f(x;\theta, \lambda + 1) dx \right] + \frac{\lambda}{\theta}\\
&\displaystyle= -\frac{\lambda}{\theta} \left[\frac{\bar{F}(VaR_p;\theta,\lambda+1)}{\bar{F}(VaR_p;\theta,\lambda)} - 1\right]\\
&\displaystyle= \mu \left[\frac{\bar{F}(VaR_p;\theta,\lambda+1)}{\bar{F}(VaR_p;\theta,\lambda)} - 1\right]
\end{array}\]

luego el resultado es:

\[\begin{array}{rl}
TVaR_p(X) &\displaystyle= \mu + \mu \left[\frac{\bar{F}(VaR_p;\theta,\lambda+1)}{\bar{F}(VaR_p;\theta,\lambda)} - 1\right]\\
&\displaystyle= \mu + \mu \left[\frac{\bar{F}(VaR_p;\theta,\lambda+1)}{\bar{F}(VaR_p;\theta,\lambda)} \right]-\mu\\
&\displaystyle= \cancel{\mu} + \mu \left[\frac{\bar{F}(VaR_p;\theta,\lambda+1)}{\bar{F}(VaR_p;\theta,\lambda)} \right]-\cancel{\mu}\\
&\displaystyle=\mu \left[\frac{\bar{F}(VaR_p;\theta,\lambda+1)}{\bar{F}(VaR_p;\theta,\lambda)} \right]
\end{array}\]

\hypertarget{teorema-2}{%
\subsubsection{Teorema}\label{teorema-2}}

sea \(X\) una variable aleatoria cuya distribución proviene de una
\textbf{REDF}. entonces \(TVaR_p(X)\) se puede escribir como:

\[TVaR_p(X)= \mu + h \sigma^2\]

donde

\(\sigma^2 = \frac{1}{\lambda}\) y\\
\[h=\frac{\partial}{\partial \theta}ln[\bar{F}(VaR_p; \theta, \lambda)]\]

\hypertarget{demostracion-2}{%
\paragraph{Demostración}\label{demostracion-2}}

\[\begin{array}{rl}
\frac{\partial}{\partial \theta}ln[\bar{F}(VaR_p; \theta, \lambda)] &\displaystyle= \frac{1}{\bar{F}(VaR_p;\theta,\lambda)}  \int_{VaR_p(x)}^{\infty}\frac{\partial}{\partial \theta} \left[e^{\lambda[\theta x - k(\theta)]} q(x;\lambda)\right]dx \\
&\displaystyle= \frac{1}{\bar{F}(VaR_p;\theta,\lambda)}  \int_{VaR_p(x)}^{\infty} \left[\lambda[x - k'(\theta)]e^{\lambda[\theta x - k(\theta)]} q(x;\lambda)\right]dx\\
&\displaystyle= \frac{1}{\bar{F}(VaR_p;\theta,\lambda)} \int_{VaR_p(x)}^{\infty} x f(x;\theta , \lambda)dx - \lambda k'(\theta)\\
&\displaystyle= \lambda [ TVaR_p(X) - \mu ]\\
&\displaystyle= [ TVaR_p(X) - \mu]/  \sigma^2
\end{array}\]

\hypertarget{tvar-normal}{%
\subsubsection{\texorpdfstring{\textbf{TVaR
Normal:}}{TVaR Normal:}}\label{tvar-normal}}

se puede demostra que la distribución normal es miembro de la
\textbf{Familia Exponencial de Dispersión Reproductiva} ya que si
observamos su densidad

\[f(x)=\frac{1}{\sqrt{2 \pi}\sigma} e^{-\frac{1}{2}\left(\frac{x - \mu}{\sigma}\right)^2}\]

la misma puede ser reexpresada como:

\[f(x)=\frac{1}{\sqrt{2 \pi}\sigma} e^{-\frac{1}{2}\left(\frac{x}{\sigma}\right)^2}e^{-\frac{1}{\sigma^2}\left(\mu x -\frac{1}{2} \mu ^2\right)}\]

donde

\(\lambda = \frac{1}{\sigma^2}\)\\
\(k(\theta)= \frac{\theta^2}{2}\) y

\[q(x; \lambda) = \frac{1}{\sqrt{2 \pi}\sigma}e^{-\frac{1}{2}\left(\frac{x}{\sigma}\right)^2}\]

luego el \(TVaR_p(X)\) es

\[TVaR_p(X)= \mu + h \sigma^2\]

donde

\(\sigma^2= \frac{1}{\lambda}\) y

\[\begin{array}{rl}
h &\displaystyle =\frac{\partial}{\partial \theta}ln[\bar{F}(VaR_p; \theta, \lambda)]\\
&\displaystyle =\frac{\partial}{\partial \theta}ln(1-\Theta[\sqrt{\lambda}(VaR_p(x)-\theta)])\\
&\displaystyle = \frac{\sqrt{\lambda \phi[\sqrt{\lambda}(VaR_p(x)-\theta)]}}{1-\Theta[\sqrt{\lambda}(VaR_p(x)- \theta)]}
\end{array}\]

lo que resulta:

\[TVaR_p(X) = \mu + \frac{1}{\sigma} \frac{\phi[\sqrt{\lambda}(VaR_p(x)- \theta)]}{1-\Theta[\sqrt(\lambda)(VaR_p(x)- \theta)]} \sigma^2\]

a continuación presentamos algunos resultados de los \(TVaR\) para
algunas distribuciones notables

\hypertarget{tvar-cauchy}{%
\subsubsection{\texorpdfstring{\textbf{TVaR
Cauchy:}}{TVaR Cauchy:}}\label{tvar-cauchy}}

\[TVaR_p(X)=\mu+\frac{\sigma}{p}\int_{0}^{p}tan\left(\pi\left(v-\frac{1}{2}\right)\right)dv\]

\hypertarget{tvar-lognormal}{%
\subsubsection{\texorpdfstring{\textbf{TVar
Lognormal:}}{TVar Lognormal:}}\label{tvar-lognormal}}

\[TVaR_p(X)=\frac{e^{\mu}}{p}\int_{0}^{p}e^{\sigma\Phi^{-1}(v)}dv\]

\hypertarget{tvar-exponencial}{%
\subsubsection{\texorpdfstring{\textbf{TVaR
Exponencial:}}{TVaR Exponencial:}}\label{tvar-exponencial}}

\[TVaR_p(X) = -\frac{1}{p\lambda}\left[log(1-p)p-p-log(1-p)\right]\]

\hypertarget{tvar-uniforme}{%
\subsubsection{\texorpdfstring{\textbf{TVaR
Uniforme:}}{TVaR Uniforme:}}\label{tvar-uniforme}}

\[TVaR_p(X) = a+\frac{p}{2}(b-a)\]

\hypertarget{tvar-weibull}{%
\subsubsection{\texorpdfstring{\textbf{TVaR
Weibull:}}{TVaR Weibull:}}\label{tvar-weibull}}

\[TVaR_p(X) = \frac{\sigma}{p}\gamma[1+\frac{1}{\alpha}, -log(1-p)]\]

\hypertarget{tvar-f}{%
\subsubsection{\texorpdfstring{\textbf{TVaR
F:}}{TVaR F:}}\label{tvar-f}}

\[TVaR_p(X) = \mu + \int_{0}^{p}F^{-1}(v)\sigma dv\]

\hypertarget{tvar-t-student}{%
\subsubsection{\texorpdfstring{\textbf{TVaR T
student:}}{TVaR T student:}}\label{tvar-t-student}}

\[TVaR_p(X) = \mu + \int_{0}^{p}T^{-1}(v)\sigma dv\]

\hypertarget{riesgo-de-liquidez}{%
\section{Riesgo de Liquidez}\label{riesgo-de-liquidez}}

El Riesgo de Liquidez es un riesgo que enfrentan todas las instituciones
financieras, en particular los Bancos, en economías inflacionarias el
efecto de la iliquidez se puede manifestar a través de la incertidumbre
presentada por el flujo de caja, dado que la dirección del mismo es
incierto, solo en circunstancias excepcionales el exceso de flujos de
caja salientes (egresos) sobre los entrantes (ingresos) darían paso a
una situación muy particular ya que los egresos representarían una gran
proporción de los activos, quedando la Institución Bancaria fuera de
solvencia lo que implicaría recurrir a otros activos menos líquidos
(liquidación inmediata de inversiones a mediano plazo), para afrontar la
iliquidez de sus acreedores naturales (Cuenta Ahorrista, Cuenta
Corrientistas), está sería una de las principales consecuencias de las
denominadas \textbf{Corridas Bancarias}.

La estrategia del Riesgo de Liquidez se fundamenta en determinar en que
grado la adquisición y mantenimiento de activos iliquidos es aceptable,
considerando los términos de evaluación, haciendo énfasis en el corto
plazo ya que un déficit de liquidez acarrearía una insuficiencia en las
reservas estatutarias e índices de solvencia obligatorias bajo las
normas de operación de las Instituciones Bancarias.

\hypertarget{clases-de-riesgo-de-liquidez.}{%
\subsection{\texorpdfstring{\textbf{Clases de Riesgo de
Liquidez.}}{Clases de Riesgo de Liquidez.}}\label{clases-de-riesgo-de-liquidez.}}

La Liquidez puede verse afectada principalmente por dos clases de
eventos diferentes cuyos efectos coinciden en la iliquidez de las
entidades, estas son:

\begin{itemize}
\item
  \textbf{Riesgo de Liquidez de Fondos:} Es el riesgo que corre la
  entidad al no ser capaz de hacer frente eficientemente a flujos de
  caja previstos e imprevistos, presentes y futuros, así como a
  aportaciones de garantías resultantes de sus obligaciones de pago, sin
  que se vea afectada su operativa diaria o su situación financiera.
\item
  \textbf{Riesgo de Liquidez de Mercado:} Es el riesgo de que una
  entidad no pueda compensar o deshacer fácilmente una posición a
  precios de mercado a causa de una insuficiente profundidad o de
  distorsiones en el mercado.
\end{itemize}

En particular en este artículo nos referiremos al Riesgo de Liquidez de
Fondos.

\hypertarget{principales-indicadores-de-liquidez.}{%
\subsection{\texorpdfstring{\textbf{Principales Indicadores de
Liquidez.}}{Principales Indicadores de Liquidez.}}\label{principales-indicadores-de-liquidez.}}

los Indicadores Contables Principales son:

\begin{itemize}
\tightlist
\item
  \textbf{RALE} o Razón de Liquidez Estructural
\item
  \textbf{RALEA} o Razón de Liquidez Estructural Ajustada\\
\item
  \textbf{RACOCAP} o Razón de Concentración de Captaciones del Público
\item
  \textbf{GAP} o Brechas de Liquidez
\end{itemize}

Estos constituyen relaciones entre los \emph{Activos Líquidos} y los
\emph{Pasivos de Vencimiento Inmediato}, en la República Bolivariana de
Venezuela los mismos están determinados a través de las cuentas
mencionadas en el artículo 15 y 16 de la Resolución 136.15 de la
Superintendencia del Sector Bancario la cual se mencionan a
continuación:

\hypertarget{activos-liquidos.}{%
\paragraph{Activos Líquidos.}\label{activos-liquidos.}}

\begin{itemize}
\tightlist
\item
  Disponibilidades.\\
\item
  Banco Central de Venezuela.\\
\item
  Bancos y Otras Instituciones Financieras del País.
\item
  Bancos y Corresponsales el Exterior.
\item
  Inversiones en Títulos Valores para Negociar.
\end{itemize}

\hypertarget{pasivos-de-vencimiento-inmediato.}{%
\paragraph{Pasivos de Vencimiento
Inmediato.}\label{pasivos-de-vencimiento-inmediato.}}

\begin{itemize}
\tightlist
\item
  Depósitos a la Vista.\\
\item
  Depósitos de Ahorro.\\
\item
  Depósitos a plazo hasta 30 días.
\item
  Depósitos a plazo.
\end{itemize}

\hypertarget{razon-de-liquidez-estructural-rale.}{%
\subsubsection{\texorpdfstring{\textbf{Razón de Liquidez Estructural}
RALE.}{Razón de Liquidez Estructural RALE.}}\label{razon-de-liquidez-estructural-rale.}}

Este indicador se genera a través de un conjunto de razones de liquidez
proyectadas, que relacionan partidas de activos y pasivos mencionadas
supra, y cuya proyección se hace para 7, 15, 30, 60 y 90 días de los
saldos contables, con base en la siguiente fórmula:

\[\text{RALE}_n = \frac{\text{Activos Líquidos hasta n días}}{\text{Pasivos de Vencimiento Inmediato hasta n días}}*100\]

dónde;

\(n=\) número de días para la proyección (7, 15, 30, 60 y 90).

\hypertarget{razon-de-liquidez-estructural-ajustada-ralea.}{%
\subsubsection{\texorpdfstring{\textbf{Razón de Liquidez Estructural
Ajustada}
RALEA.}{Razón de Liquidez Estructural Ajustada RALEA.}}\label{razon-de-liquidez-estructural-ajustada-ralea.}}

Este indicador mide la capacidad que tiene el banco para cumplir con los
retiros imprevisto que se pueden presentar en las cuentas corrientes, de
ahorros, depósitos a plazos, y otras obligaciones a vencimiento dentro
de los plazos establecidos, excluyendo los fondos comprometidos para
cumplir con los requerimientos del encaje legal vigente.

\[\text{RALEA}_n = \frac{\text{Activos Líquidos Ajustados hasta n días}}{\text{Pasivos de Vencimiento Inmediato Ajustados hasta n días}}*100\]

Nótese:

Para los fines del cálculo de este indicador los activos líquidos
deberán ser ajustados deduciendo el monto del encaje legal tomando en
cuenta la proporción de reservas de encaje legal que se liberaría por
los retiros estimados de depósitos, sobre la base de la experiencia
histórica de situaciones de retiros masivos de captaciones del público,
producto de eventos sistemáticos y no sistemáticos.

También, los pasivos de vencimiento inmediato deberán ser ajustados
considerando su porción volátil o susceptible de retiro, la cual será
determinada mediante fluctuación esperada de las mismas a través de
modelos estadísticos y/o estocásticos que simule la estimación de la
volatilidad de dichos rubros.

\hypertarget{razon-de-concentracion-de-captaciones-del-publico-racocap.}{%
\subsubsection{\texorpdfstring{\textbf{Razón de Concentración de
Captaciones del Público}
RACOCAP.}{Razón de Concentración de Captaciones del Público RACOCAP.}}\label{razon-de-concentracion-de-captaciones-del-publico-racocap.}}

la manera de calcular este indicador es a través del cociente de
liquidez diario resultante de la sumatoria de los veinte (20) mayores
saldos promedios de los últimos siete (7) días de depósitos que posean
personas naturales o jurídicas en todos los productos masivos del banco
en forma consolidada, dividido entre el total del saldo promedio de los
últimos siete (7) días de la cartera de depositantes del banco.

\[\text{RACOCAP} = \frac{\text{(20) Mayores Saldos Promedios Últimos siete (7) días de Depósitos}}{\text{Saldos Promedios Últimos siete (7) días de la Cartera de Depositantes}}*100\]

\hypertarget{monitoreo-del-riesgo-de-liquidez.}{%
\subsubsection{Monitoreo del Riesgo de
Liquidez.}\label{monitoreo-del-riesgo-de-liquidez.}}

Se entiende por monitoreo del riesgo de liquidez, al proceso de
evaluación continua de las posiciones de riesgo de liquidez asumidas por
la Institución Financiera, así como al funcionamiento de todo el sistema
de gestión del riesgo de liquidez. Este proceso ayuda a detectar y
corregir anticipadamente las deficiencias que pudieran existir en la
asunción de políticas, el desarrollo de procesos y procedimientos, y
cualquier otro aspecto relacionado con la gestión del riesgo de
liquidez.

El alcance del monitoreo abarca todos los aspectos de la gestión del
riesgo de liquidez, en un ciclo dinámico acorde con la naturaleza del
negocio y el volumen, tamaño y complejidad de las operaciones de la
Institución Financiera.

En el marco de la fase de monitoreo del riesgo de liquidez, el Comité de
Riesgos podrá solicitar las actas de las reuniones de los otros comités,
creados en la Institución Financiera (ALCO, de Crédito, de Tesorería e
Inversiones, y otros), con el objeto de verifi car que las
recomendaciones e instrucciones emanadas del Comité de Riesgos, con
relación al riesgo de liquidez, hayan sido incorporadas por las áreas
comerciales o de negocios. Los exámenes practicados por la Unidad de
Auditoria Interna podrán verificar el grado de implementación y
cumplimiento de tales recomendaciones.

\hypertarget{divulgacion-de-la-informacion-y-comunicacion-oficial-del-riesgo-de-liquidez}{%
\subsubsection{Divulgación de la Información y Comunicación Oficial del
Riesgo de
Liquidez}\label{divulgacion-de-la-informacion-y-comunicacion-oficial-del-riesgo-de-liquidez}}

La fase de divulgación constituye el último eslabón del proceso de
gestión del riesgo de liquidez, y consiste en la distribución de
información apropiada sobre el riesgo de liquidez al Directorio,
Gerencia, personal, así como interesados externos tales como: clientes,
proveedores, reguladores y accionistas. Esta información puede ser
interna o externa, y debe incluir información financiera y operativa.

Con relación a la divulgación externa, la Institución Financiera debe
ajustarse al marco regulatorio existente, respetando las limitaciones y
restricciones si las hubiera.

En cuanto se refiere a la divulgación interna, ésta dependerá de las
políticas adoptadas internamente por la Institución Financiera para este
propósito específico, debiendo observar, al menos, los siguientes
aspectos:

\begin{itemize}
\item
  El principio fundamental es que todos los funcionarios de la
  Institución Financiera deben conocer la matriz de riesgos
  institucional. Asimismo, deben conocer el grado de exposición de la
  entidad a los distintos riesgos, entre ellos el de liquidez.
\item
  El grado de profundidad del proceso de divulgación de la matriz de
  riesgos, debe variar según las funciones y grado jerárquico de los
  receptores.
\item
  La definición expresa del contenido y la periodicidad del flujo de la
  información. El establecimiento de mecanismos de verifi cación del
  cumplimiento de las políticas de divulgación.
\end{itemize}

La gestión de riesgos encuentra en la información, un elemento clave
para estructurar un buen sistema de administración de riesgos y alcanzar
los objetivos de minimización de pérdidas para la entidad.

En el caso específico del riesgo de liquidez, el sistema de información
debe ser lo sufi cientemente flexible para brindar toda la información
que se requiera para cumplir con todas las etapas de la gestión de
riesgos: identifi car, medir, monitorear, controlar, mitigar y divulgar
el riesgo de liquidez. Así por ejemplo, como se pudo apreciar en la
sección sobre metodologías, el análisis de brechas de liquidez requiere
la clasifi cación de activos y pasivos por bandas de renovación o
vencimiento; por lo tanto, el sistema de información de la EIF debe
tener la capacidad de procesar automáticamente la información, de manera
de clasifi carla por bandas, con base en una fecha de corte o de
análisis determinado.

Dicho sistema debe permitir, además, incorporar los porcentajes de
renovación, precancelación, morosidad, etc. que la Institución
Financiera considere relevantes para generar el escenario de liquidez
esperado, así como los escenarios de estrés. Asimismo, el sistema debe
estar en capacidad de incorporar metodologías estadísticas u otras
necesarias para realizar estimaciones, proyecciones, cálculo de la
porción estable y volátil de los productos de plazo indeterminado,
ejercicios de simulaciones de escenarios, y otras relacionadas con la
medición del riesgo de liquidez. El sistema de información debe generar
reportes de exposición al riesgo de liquidez para ser analizados por el
Comité de Riesgos.

El sistema de información debe permitir el almacenamiento sistematizado
de las bases de datos y de los reportes generados, y debe contar con
mecanismos de seguridad y niveles de acceso apropiados para un óptimo
funcionamiento del mismo.

Debido a la complejidad de los cálculos que podrían realizarse y al
volumen de transacciones que podría existir en el procesamiento de la
información para la gestión del riesgo de liquidez, el sistema de
información de la Institución Financiera debe contener mecanismos de
validación de la información y de los procesos a ejecutarse, a fin de
minimizar cualquier tipo de error que pudiera presentarse en el manejo
operativo del mismo.

En Venezuela la divulgación y comunicación oficial de los riesgos en
particular del riesgo de liquidez está regulada por la disposición
136.15 la cual indica que la información debeb ser divulgada a través de
un mecanismo electrónico denominado \textbf{Archivo de Transmisión 28} o
el \textbf{AT28}, el cual contiene información detallada de todos los
aspectos del riesgo de liquidez como los ratios de liquidez, las brechas
Contractuales, Esperadas y Estresadas así como la razon de riesgo de
liquidez y su distribución proporcional con respecto a la cartera.

El ente que centraliza la información es la \textbf{Superintendencia de
las Instituciones del Sector Bancario} (SUDEBAN) a través del
\textbf{Sistema de Información Financiera} (SIF).

\hypertarget{brechas-de-liquidez-gap}{%
\section{Brechas de Liquidez (GAP)}\label{brechas-de-liquidez-gap}}

Las bandas de liquidez o GAP de liquidez es una estimación de la
estructura del riesgo de liquidez proyectada a lo largo de un período
con el objeto de realizar una estimación fija del mismo.

para cálcularla debemos pasar por un proceso estádistico que implica un
conjunto de contrastes de hipótesis con el fin de establecer o
determinar la distribución probabilistaca asociada a la población tipo,
\(VaR\) y \(TVaR\).

El análisis de las brechas de liquidez tiene como propósito establecer a
partir de los vencimientos de los activos y pasivos tanto contractuales
como esperados, el nivel de suficiencia de recursos líquidos, una
formulación sencilla viene dada de la siguiente manera:

\[\text{GAP}_n = \sum \text{Flujos de Caja Entrantes} - \sum \text{Flujos de Caja Salientes}\]

Nótese:

La parte que se refiere a los egresos (flujos de caja salientes) se
puede dividir en una porción que depende de los compromisos fijos o
contractuales que vienen dado de forma cierta denominada \emph{porción
estable} y otra que depende de los escenarios esperados asociados
eventos susceptibles de medida por modelos probabilísticos, estocásticos
o estadísticos que se denomina \emph{porción volátil}

\hypertarget{de-la-porcion-volatil.}{%
\subsubsection{De La Porción Volátil.}\label{de-la-porcion-volatil.}}

La volatilidad de los depósitos está definida como un \textbf{VaR}
(Value at Risk por sus siglas en inglés o Valor en Riesgo en idioma
español), cuya medida depende de un nivel de confianza del 95\% y 99\%
en un período de liquidación de las posiciones de 7 días. Las
Distribuciones Probabilísticas que dan paso al cálculo del VaR son
ajustadas a través de pruebas estadísticas especiales denominadas
\emph{Pruebas de Bondad de Ajuste} con una muestra de 252 observaciones
de frecuencia diaria.

En todo caso cuando se trate de bancos con información de sus depósitos
inferior al período establecido, la porción volátil de los depósitos no
podrá ser menor al 10\% del saldo contable al día anterior a la
estimación.

la variabilidad de los depósitos se hace a través del cálculo de sus
rendimientos que en su versión más sencilla tenemos lo que se denomina
\textbf{Retorno Simple}:

\[\begin{array}{rl}
R_{t}(n) &\displaystyle= \left(1+R_{t}\right) \left(1+R_{t-1}\right) \left(1+R_{t-2}\right) \ldots \left(1+R_{t-n+1}\right) -1\\
&\displaystyle= \frac{P_t}{P_{t-1}} \frac{P_{t-1}}{P_{t-2}} \ldots \frac{P_{t-n+1}}{P_{t-n}}-1\\
&\displaystyle= \frac{P_{t}-P_{t-n}}{P_{t-n}}
\end{array}\]

considerando que los intereses y la tasa de cambio es considerada
continuamente compuesta podemos expresar los retornos en términos de su
serie de tiempo diferenciada logaritmica:

\[Y_{t}(n)=\ln(1+R_{t})=\ln \left(\frac{P_{t}}{P_{t-1}}\right)\]

Donde;

\(X_t\): Es el saldo de Pasivo sin vencimiento contractual en el período
o día \(t\).\\
\(X_{t-1}\): Es el saldo del Pasivo sin Vencimiento Contractual en el
período o día \(t-1\).

La razón fundamental por el cual el VaR se calcula a través de los
rendimientos es porque estos tienen propiedades estadísticas que
resultan más manejables a la hora de una estimación o pronóstico ya que
son Estacionarios y ergódicos.

luego, utilizando los resultados de las Pruebas de Bondad de Ajuste se
calcula el VaR con un \(\alpha\)\% de confianza y se aplica la siguiente
forma para calcular la porción volátil:

\[P_{VaR_{\alpha}} = S_n * VaR_{\alpha} * \sqrt{t}\]

Donde;

\(t=\) Período de liquidación\\
\(S_n=\) Saldo al día \(n\), es decir, el último saldo real de los
depósitos\\
\(VaR_{\alpha}=\) Valor a Riesgo asociado a nivel de confianza calculado
bajo la distribución que resulte de las pruebas de bondad de ajuste

\hypertarget{escenarios-de-la-bandas-de-liquidez.}{%
\subsubsection{Escenarios de la Bandas de
Liquidez.}\label{escenarios-de-la-bandas-de-liquidez.}}

\hypertarget{escenario-contractual.}{%
\paragraph{Escenario Contractual.}\label{escenario-contractual.}}

El escenario contractual se construye tomando en cuenta las fechas de
recuperación de activos o vencimiento de pasivos contractualmente
definidas, con la finalidad de ubicar los saldos de cada rubro del
activo y del pasivo en bandas temporales, según su plazo residual de
exigibilidad o de vencimiento, respectivamente.

En el caso de productos con plazo indeterminado, es decir, sin fecha de
vencimiento contractual, como son los depósitos a la vista y en caja de
ahorro, es recomendable que su distribución en las bandas de tiempo, se
realice utilizando metodologías basadas en el análisis de su
volatilidad, estimando la caída máxima esperada considerando un
determinado nivel de confianza.

Luego de haber distribuido los saldos en las distintas bandas de tiempo,
se procede a generar, para cada banda, la diferencia entre las partidas
de activo y pasivo calculando de esta manera la brecha de liquidez.

Con base en los montos de las brechas de liquidez calculados para cada
banda de tiempo, se procede a realizar el cálculo de la brecha
acumulada, a través de la acumulación de las brechas liquidez
individuales. De esta manera, la brecha acumulada para una determinada
banda de tiempo se calcula sumando a la brecha liquidez correspondiente
a dicha banda, las brechas simples de las bandas de tiempo precedentes,
representando el total acumulado de diferencias entre partidas de activo
y pasivo hasta la banda en cuestión.

Si la brecha de liquidez acumulada a un determinado plazo es negativa,
es decir, si el saldo acumulado de diferencias entre activo y pasivo es
deficitario, este monto es considerado como liquidez en riesgo.

Por tanto, el análisis de brechas de líquidez requiere que la
Institución Financiera adopte políticas en relación a la fijación de
límites de exposición para la brecha de liquidez acumulada negativa, a
nivel de moneda y en forma consolidada, pudiendo establecerse como un
monto máximo expresado en unidades monetarias y/o como un porcentaje
máximo en relación a los activos; los importes en exceso sobre dichos
límites serán considerados como ``Liquidez en Riesgo''. No obstante esta
recomendación, es importante reconocer que el establecimiento de límites
a la brecha de liquidez acumulada negativa, no necesariamente debe
implicar la ausencia de posiciones de liquidez en riesgo, pues bien
podría admitirse un cierto nivel de tolerancia.

De manera complementaria, también podrían establecerse límites para la
relación entre activos y pasivos, lo que implicaría de antemano la
aceptación o no de la existencia de liquidez en riesgo.

Los límites adoptados internamente por la Institución Financiera deben
ser el resultado de un análisis riguroso y de estudios especializados
llevados a cabo por la unidad para estos fines.

\hypertarget{escenario-esperado.}{%
\paragraph{Escenario Esperado.}\label{escenario-esperado.}}

Como se ha manifestado, en el escenario contractual no se toman en
cuenta comportamientos que no sean aquellos puramente contractuales. Un
ajuste al escenario contractual es el que corresponde al escenario
esperado.

En el escenario esperado se incorporan renovaciones, pre-cancelaciones,
morosidad, y cualquier otro tipo de comportamientos que normalmente se
registran en los diferentes rubros del balance general de una
Institución Financiera. Para ello se deben estimar los porcentajes o
proporciones de ocurrencia de estos casos, con base en estudios
especialmente desarrollados por la Institución Financiera para realizar
estos cálculos, en función a la propia historia de la entidad contenida
en sus bases de datos. Los estudios podrían considerar por ejemplo, el
cálculo de la recurrencia de renovaciones de depósitos a plazo fijo, si
éstos revelaran por ejemplo, que normalmente, para un determinado nivel
de confianza, las renovaciones representan un 80\% de los casos, los
flujos de salida de fondos en las bandas de tiempo correspondientes a
este producto, deberían ajustarse conforme a esta estadística histórica;
de este modo, la salida de recursos estimada correspondería únicamente
al 20\% de los casos restantes. Las estimaciones pueden realizarse en
forma global, aplicable a todas las bandas de tiempo o,
alternativamente, en forma separada para cada banda de tiempo.

Se debe señalar en este caso, el escenario de liquidez no es tan
desfavorable como en el escenario contractual, en razón a que únicamente
en dos bandas temporales (hasta 60 y 90 días) existe posición de
liquidez en riesgo. Esto se debe a la incorporación del porcentaje de
renovación de los depósitos a plazo.

\hypertarget{escenario-estresado.}{%
\paragraph{Escenario Estresado.}\label{escenario-estresado.}}

Es recomendable que en el análisis de liquidez se generen, además,
escenarios de estrés o simulaciones de posibles situaciones extremas con
corridas de fondos, asumiendo, por ejemplo, que todos los depósitos a la
vista y en cuentas de ahorro pudieran salir de la Institución Financiera
en una o dos semanas, o en el primer mes, suponiendo además que no
ocurran renovaciones de depósitos a plazo. Estos escenarios pondrían a
prueba la situación de liquidez de la Institución Financiera bajo
condiciones extremas, no siendo aplicable el análisis de volatilidad
recomendado para situaciones normales.

Las cantidades calculados para las posiciones de liquidez en riesgo ante
situaciones extremas, posibilitan a la Institución Financiera estimar la
cuantía de recursos que necesitaría para atender emergencias derivadas
de esas eventualidades. Con base en dichas estimaciones se debería
planificar fuentes alternativas de financiamiento y estructurar un Plan
de Contingencias.

\hypertarget{enfoque-actuarial}{%
\section{Enfoque Actuarial}\label{enfoque-actuarial}}

Una de las persepectivas más retadoras de este trabajo es resolver la
caracterización de eventos para la cuantificación del riesgo de liquidez
asumiendo que el horizonte temporal de las misma es dinámico. Desde el
enfoque tradicional el horizonte temporal se considera estático o esta
``congelado''. Por las características de los datos tomaremos en
consideración no solamente la severidad del evento sino también el
número de eventos, esto es, significa que para considerar el saldo o el
monto en retiros asumiremos una variable aleatoria compuesta en donde
tanto la severidad como el numero de eventos, dando paso al modelo de
pérdida agregada. Además con la aplicación de este modelo y la
perspectiva integral en materia de riesgo queda sentada la basde para la
construcción de un modelo de Ruina Bancario cuya propuesta abordaremos
al final de este capítulo.

\hypertarget{modelo-de-perdida-agregado}{%
\subsection{Modelo de Pérdida
Agregado}\label{modelo-de-perdida-agregado}}

En el suscinto modelo se calcula el monto total de la partida a través
de la suma compuesta de variables aleatorias independientes, y para esta
suma compuesta hay que determinar la distribución. Esto es:

\[S=\sum_{i=1}^{N}X_i~~con~S=0 ~si~N=0\]

donde \(N\) es el número de retiros de las cuentas y \(X_i\) es el monto
(severidad) de cada retiro la cual se asume estrictamente positivo por
como est'a definida la variable aleatoria.

Estudiaremos la función de distribución de \(S\) y luego analizaremos
una version de la misma a tiempo continuo a través del marco de la
teoría de ruina.

El suspuesto clasico del monto \(S\) requiere que \(N\) sea
independiente del monto de los retiros. tambien asumimos que los \(X_i\)
son variables aleatorias independientes e identicamente distribuidas,
luego la función de distribución queda de la siguiente manera:

\[F_{S}(s)=\mathbb{P}(N=n)\mathbb{P}(X_1+...+X_n\leq s)=\sum_{i=0}^{+\infty}\mathbb{P}(N=n)F_{X}^{*n}(s)\]

donde \(F_{X}^{*n}\) es producto convolución de orden n-ésimo de
\(F(X)\)

En general, la distribución de la suma \(X_1, ..., X_n\) no
necesariamente tiene la misma distribución que \(X\). Una solución a
este problema fue propuesto por Panjer (1981), la cual provee una
formula recursiva en el caso que \(X\) tenga una distribución discreta y
\(N\) pertenezca a una \((a,b,n)\) familia de distribución. luego la
formula de recursiva para la función de masa de \(p_S\) es:

\[p_S(s)=\frac{[p_X(1)-(a+b)p_X(0)]p_X(s)+\sum_{y=1}^{s\wedge m}(a+by/x)p_X(y)p_S(s-y)}{1-ap_X(0)}\]

donde \(s \in \mathbb{N}\), \(X\) tiene una distribución
\(\{0,1,...m\}\) con una función de masa \(p_X\), \(N\) pertenece a una
\((a,b,0)\) familia de distribución, empezando con
\(p_S(0)=G_N(p_X(0))\) con \(G_N\) como la función generadora de
probabilidades.

El criterio de parada de esta recursión es cuando la suma de las
probabilidades esté arbitrariamente cercano a 1 se detiene la misma.

En la prática la variable del monto de los retiros no es discreta, sin
embargo, pueden ser discretizadas.

Para realizar la discretización de la variable existen tres métodos, se
puede discretizar por exceso, por defecto o de manera insesgada.

La discretización por excesos se calcula a través de la diferencia hacia
adelante esto es:

\[\bar{f}(x)=F_X(x+h)-F_X\] La discretización por defecto se calcula con
la diferencia hacia atrás, de la siguiente manera:

\[\bar{f}(x)=F_X(x)-F_X(x-h)\]

Asímismo, la discretización insesgada se calcula:

\[\bar{f}(x)=(2\mathbb{E}(X\wedge x)-\mathbb{E}(X\wedge x-h)-\mathbb{E}(X \wedge x+h))/h\]
donde \(h\)es el paso o amplitud de discretización.

Otra alternativa son las aproximaciones basadas en la distribución
normal.

\hypertarget{aproximacion-normal-y-normal-power}{%
\subsubsection{Aproximación Normal y Normal
Power}\label{aproximacion-normal-y-normal-power}}

Esta aproximación viene dada por:

\[F_S(x) \approx \Phi\left(\frac{x-\mathbb{E}(S)}{\sigma(S)}\right)\]

Asímismo, la aproximación Normal Power viene dada por:

\[F_S(x) \approx \Phi\left(-\frac{3}{sk(S)}+\sqrt{\frac{9}{sk(S)}+1+\frac{6}{sk(S)}\frac{x-\mathbb{E}(S)}{\sigma(S)}}\right)\]

donde

\[sk(S)=\frac{sk(N)var(N)^{3/2}\mathbb{E}(X)^3+3var(N)\mathbb{E}(X)var(X)+ \mathbb{E}(N)sk(X)var(X)^{3/2}}{var(S)^{3/2}}\]

\hypertarget{teoria-de-ruina}{%
\subsubsection{Teoría de Ruina}\label{teoria-de-ruina}}

La Teoría de Ruina se trata de un procesos estocástico relacionado o
vinculado con la salud de ciertas entidades financieras, aseguradoas y
de inversión. En el proceso se caracterizan las reservas de riesgo, en
el caso bancario, serían reservas de dinero asociados con los créditos,
el encaje legal, provisiones tanto genéricas como específicas. Como
modelo inicial consideramos dicha reserva de riesgo esta representada
por:

\[U_t=u+ct-\sum_{i=1}^{N_t}X_i\]

donde \(u\) es la reserva inicial de las cuentas. \(c\) es la variación
máxima volatil o VaR de liquidez. \(X_i~~\forall i \geq1\) son los
montos de los retiros sucesivos. \(N_t~~\forall t \geq0\) es el proceso
que describe como llegan los retiros, los mismo se asumen como un
proceso de Poisson con intensidad lambda.

En el futuro, o como propuesta de trabajo subsiguiente podemos desde
este enunciado desarrollar una \textbf{Teoría de Riesgo Bancaria}

\hypertarget{rliquidity}{%
\section{Rliquidity}\label{rliquidity}}

\hypertarget{r-y-el-paquete-rriskdistribution}{%
\subsubsection{\texorpdfstring{R y el Paquete
\textbf{rriskDistribution}}{R y el Paquete rriskDistribution}}\label{r-y-el-paquete-rriskdistribution}}

El paquete \texttt{rriskDistributions} provee una colección de funciones
para la estimación de parámetros de distribuciones discretas y continuas
relacionadas con distribuciones de pérdida y con la teoría matemática
del riesgo.

la misma provee pruebas paramétricas de bondad de ajuste de
distribuciones probabilísticas dado los datos o sus cuantiles. El
algoritmo ajusta distribuciones sin necesidad de la sistencia del
usuario y sin especificar ninguna familia de distribuciones.

\hypertarget{r-y-el-paquete-vares}{%
\subsubsection{\texorpdfstring{R Y el Paquete
\textbf{VaRES}}{R Y el Paquete VaRES}}\label{r-y-el-paquete-vares}}

El Paquete de R denominado \textbf{VaRES}, calcula los Valores a Riesgo
( \textbf{VaR}) y la Expectativa a Corto Plazo ( \textbf{ES}), que
constituyen dos de las medidas más populares del Riesgo Financiero para
más de 100 (cien) distribuciones paramétricas, incluyendo todas las
comúnmente conocidas.

\#Bibliografía

\#Anexos

\end{document}
